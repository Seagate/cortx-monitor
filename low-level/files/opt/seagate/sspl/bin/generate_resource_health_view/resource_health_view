#!/usr/bin/python3.6

# Copyright (c) 2020 Seagate Technology LLC and/or its Affiliates
#
# This program is free software: you can redistribute it and/or modify it under the
# terms of the GNU Affero General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
# PARTICULAR PURPOSE. See the GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License along
# with this program. If not, see <https://www.gnu.org/licenses/>. For any questions
# about this software or licensing, please email opensource@seagate.com or
# cortx-questions@seagate.com.

import json
import os
import sys
import socket
import time
import argparse
import consul
import psutil
import subprocess
import traceback
import tempfile
import dbus
from dbus import SystemBus, Interface, Array
from framework.utils.service_logging import logger
import warnings
warnings.filterwarnings(action='ignore',module='cryptography')
from framework.utils.store_factory import store
from framework.utils.ipmi_client import IpmiFactory
from framework.utils.sysfs_interface import SysFS
from framework.utils.tool_factory import ToolFactory
from framework.base.sspl_constants import (component, CONSUL_HOST, CONSUL_PORT, node_key_id, PRODUCT_FAMILY,
    storage_type, server_type, NODE_ID, SITE_ID, RACK_ID, DATA_PATH
)

class SSPLHealthView(object):
    """docstring for SSPLHealthView"""

    RESOURCE_HEALTH_VIEW_FILE = 'resource_health_view.json'
    RESOURCE_HEALTH_VIEW_PATH = '/tmp/' + RESOURCE_HEALTH_VIEW_FILE
    TEMPLATE_SCHEMA_FILE = f'/opt/seagate/{PRODUCT_FAMILY}/sspl/bin/generate_resource_health_view/resource_health_view_template.json'

    ENCL_MANIFEST_PATH = '/tmp/encl_manifest.json'
    NODE_MANIFEST_PATH = '/tmp/node_manifest.json'

    STORAGE_TYPE_JBOD = 'jbod'
    STORAGE_TYPE_RBOD = 'rbod'
    STORAGE_TYPE_VIRTUAL = 'virtual'

    SERVER_TYPE_VIRTUAL = 'virtual'
    SERVER_TYPE_PHYSICAL = 'physical'

    def __init__(self):

        persistent_data_location = sys_data_path
        storage_encl_dir = persistent_data_location + 'encl/frus/'
        self.encl_disks_filename = storage_encl_dir + 'disks/'
        self.encl_psus_filename = storage_encl_dir + 'psus/psudata.json'
        self.encl_controllers_filename = storage_encl_dir + 'controllers/controllerdata.json'
        self.encl_fans_filename = storage_encl_dir + 'fanmodules/fanmodule_data.json'
        self.encl_sideplane_exp_filename = storage_encl_dir + 'sideplane_expanders/sideplane_expanders_data.json'
        self.encl_logical_volumes_filename = storage_encl_dir + 'logical_volumes/logicalvolumedata.json'

        self.jbod_disks_filename = persistent_data_location + 'server/systemd_watchdog/disks/disks.json'

        encl_fru = 'enclosure:fru'
        self.encl_disk_resource_type = encl_fru + ":disk"
        self.encl_controller_resource_type = encl_fru + ":controller"
        self.encl_fan_resource_type = encl_fru + ":fan"
        self.encl_psu_resource_type = encl_fru + ":psu"
        self.encl_sideplane_resource_type = encl_fru + ":sideplane"
        self.encl_logical_volume_resource_type = f"enclosure:{PRODUCT_FAMILY}:logical_volume"
        self.encl_sas_resource_type = "enclosure:interface:sas"

        self.undesired_vals = ["N/A", ""]
        self.NODE_REQUEST_MAP = {
            "disk" : "Drive Slot / Bay",
            "fan" : "Fan",
            "psu" : "Power Supply"
        }

        self.SAS_RESOURCE_ID = "SASHBA-0"
        self.node_interface_data = ['sas_port', 'network_cable']
        self.NW_CBL_CARRIER_FILE = "/sys/class/net/{}/carrier"
        
        self.encl_hw_specifics_api = 'configuration'

        self.SITE_ID = sys_site_id
        self.RACK_ID = sys_rack_id
        self.HOST_NAME = socket.getfqdn()
        self.NODE_ID = sys_node_id
        self.CLUSTER_ID = sys_cluster_id
        self.fru_id_map = None
        self.sensor_id_map = None
        self.ipmi_fru_lst = ['disk', 'fan', 'psu']
        self.sensor_list = ['temperature', 'current', 'voltage']
        self.tried_alt_ip = False
        self.correct_mc_config = True
        self.storage_type = storage_type
        self.server_type = server_type
        self.jbod_drive_by_device_name = {}
        ipmi_factory = IpmiFactory()
        self._executor = ipmi_factory.get_implementor("ipmitool")
        try:
            self._resource_health_view = json.loads(open(self.TEMPLATE_SCHEMA_FILE).read())

        except Exception as e:
            print("Error in reading resource health view template file: {0}".format(e))
            sys.exit(1)

        self._resource_health_view['cluster'].update({'cluster_id':self.CLUSTER_ID})
        self._resource_health_view['cluster']['sites'][self.SITE_ID] =\
            self._resource_health_view['cluster']['sites'].pop('site_id')

        self._resource_health_view['cluster']['sites'][self.SITE_ID]['rack']\
            [self.RACK_ID] = self._resource_health_view['cluster']['sites']\
                [self.SITE_ID]['rack'].pop('rack_id')

    def run(self, args):
        health_view_created = False
        if args.path:
            self.RESOURCE_HEALTH_VIEW_PATH = args.path
            if os.path.exists(args.path):
                self.RESOURCE_HEALTH_VIEW_PATH = args.path if args.path.endswith('/') else args.path+'/'
                if args.support and args.encl:
                    self.ENCL_MANIFEST_PATH = self.RESOURCE_HEALTH_VIEW_PATH + "encl_manifest.json"
                if args.support and args.node:
                    self.NODE_MANIFEST_PATH = self.RESOURCE_HEALTH_VIEW_PATH + "node_manifest.json"
                if not args.support:
                    self.RESOURCE_HEALTH_VIEW_PATH += self.RESOURCE_HEALTH_VIEW_FILE
            else:
                print("Given path doesn't exist")
                sys.exit(1)

        if not args.support:
            if os.path.exists(self.RESOURCE_HEALTH_VIEW_PATH):
                print("Resource Health view JSON file already exists, overriding ...!")

            if args.encl and self.storage_type == self.STORAGE_TYPE_JBOD:
                try:
                    storage_encl_health_json = self._resource_health_view['cluster']['sites']\
                                                        [self.SITE_ID]['rack'][self.RACK_ID]\
                                                        ['nodes']['storage_encl']
                except Exception as e:
                    print("Error while extracting values from health view json % : " % e)
                    return False
                
                for category in ['sw', 'interfaces', 'platform_sensors']:
                    del self._resource_health_view['cluster']['sites']\
                                                            [self.SITE_ID]['rack'][self.RACK_ID]\
                                                            ['nodes']['storage_encl'][category]
                for sub_category in ['psus', 'controllers', 'fans', 'sideplane_expander']:
                    del self._resource_health_view['cluster']['sites']\
                                                            [self.SITE_ID]['rack'][self.RACK_ID]\
                                                            ['nodes']['storage_encl']['hw']['fru'][sub_category]
                self.build_health_view_storage_jbod_cache(storage_encl_health_json)
                health_view_created = True
            
            elif args.encl and self.storage_type == self.STORAGE_TYPE_RBOD:
                try:
                    storage_encl_health_json = self._resource_health_view['cluster']['sites']\
                                                        [self.SITE_ID]['rack'][self.RACK_ID]\
                                                        ['nodes']['storage_encl']
                except Exception as e:
                    print("Error while extracting values from health view json % : " % e)
                    return False
                self.build_health_view_storage_encl_cache(storage_encl_health_json, 'hw')
                if self.correct_mc_config:
                    self.build_health_view_storage_encl_cache(storage_encl_health_json, 'sw')
                    self.build_health_view_storage_encl_cache(storage_encl_health_json, 'interfaces')
                    self.build_health_view_storage_encl_cache(storage_encl_health_json, 'platform_sensors')
                    health_view_created = True
                else:
                    print("Management controller IPs are not configured properly on node or consul", end=" ")
                    print("or it is inaccessible for the current node.")
                    print("Ignored to collect enclosure health view data.")

            elif self.storage_type == self.STORAGE_TYPE_VIRTUAL:
                self._resource_health_view['cluster']['sites']\
                                                    [self.SITE_ID]['rack'][self.RACK_ID]\
                                                    ['nodes']['storage_encl'].clear()

            elif not args.encl:
                del self._resource_health_view['cluster']['sites']\
                                                        [self.SITE_ID]['rack'][self.RACK_ID]\
                                                        ['nodes']['storage_encl']

            if args.node and self.server_type == self.SERVER_TYPE_VIRTUAL:
                try:
                    node_health_json = self._resource_health_view['cluster']['sites']\
                                                        [self.SITE_ID]['rack'][self.RACK_ID]\
                                                        ['nodes']['node:'+self.HOST_NAME] =\
                                                        self._resource_health_view['cluster']['sites']\
                                                        [self.SITE_ID]['rack'][self.RACK_ID]\
                                                        ['nodes'].pop('node')
                    node_health_json.update({'node_id':self.NODE_ID})
                except Exception as e:
                    print("Error while extracting values from health view json % : " % e)
                    return False

                for category in ['hw', 'interfaces', 'platform_sensors']:
                    del self._resource_health_view['cluster']['sites']\
                                                        [self.SITE_ID]['rack'][self.RACK_ID]\
                                                        ['nodes']['node:'+self.HOST_NAME][category]
                self.build_health_view_node_server_cache(node_health_json, 'os')
                health_view_created = True
            
            elif args.node:
                try:
                    node_health_json = self._resource_health_view['cluster']['sites']\
                                                        [self.SITE_ID]['rack'][self.RACK_ID]\
                                                        ['nodes']['node:'+self.HOST_NAME] =\
                                                        self._resource_health_view['cluster']['sites']\
                                                        [self.SITE_ID]['rack'][self.RACK_ID]\
                                                        ['nodes'].pop('node')
                    node_health_json.update({'node_id':self.NODE_ID})
                except Exception as e:
                    print("Error while extracting values from health view json % : " % e)
                    return False
                self.build_health_view_node_server_cache(node_health_json, 'hw')
                self.build_health_view_node_server_cache(node_health_json, 'platform_sensors')
                self.build_health_view_node_server_cache(node_health_json, 'interfaces')
                self.build_health_view_node_server_cache(node_health_json, 'os')
                health_view_created = True

            elif not args.node:
                del self._resource_health_view['cluster']['sites']\
                                    [self.SITE_ID]['rack'][self.RACK_ID]\
                                    ['nodes']['node']

            self.write_content_in_file(self.RESOURCE_HEALTH_VIEW_PATH, self._resource_health_view,
                                        'resource health view')

            if health_view_created:
                print('Resource Health View Json Created Successfully..! :%s' % self.RESOURCE_HEALTH_VIEW_PATH)

        else:
            support_common_data = {
                "cluster_id": self.CLUSTER_ID,
                "site_id": self.SITE_ID,
                "rack_id": self.RACK_ID,
                "node_id": self.NODE_ID
            }
            if args.encl and args.support and self.storage_type == self.STORAGE_TYPE_RBOD:
                encl_support_data = {}
                encl_support_data.update(support_common_data)
                encl_data_response = self.build_encl_hw_specifics_instances()
                if encl_data_response and 'enclosures' in encl_data_response:
                    encl_support_data["enclosure_wwn"] = encl_data_response["enclosures"][0]["enclosure-wwn"]
                    encl_support_data["hw_specifics"] = encl_data_response
                    self.write_content_in_file(self.ENCL_MANIFEST_PATH, encl_support_data,
                                                'enclosure support data')
                    print('Enclosure Support data Json Created Successfully..! :%s' % self.ENCL_MANIFEST_PATH)

                else:
                    print("Management controller IPs are not configured properly on node or consul", end=" ")
                    print("or it is inaccessible for the current node.")
                    print("Ignored to collect enclosure manifest data.")

            if args.node and args.support:
                node_support_data = {}
                node_support_data.update(support_common_data)
                node_support_data.update({"hostname": self.HOST_NAME})
                node_support_data["hw_specifics"] = self.build_node_hw_specifics_instances()
                self.write_content_in_file(self.NODE_MANIFEST_PATH, node_support_data,
                                            'node support data')
                print('Node Support data Json Created Successfully..! :%s' % self.NODE_MANIFEST_PATH)

    def build_health_view_storage_encl_cache(self, storage_encl_health_json, category):

        if category == 'hw':
            disk_data = storage_encl_health_json['hw']['fru']['disks']
            disks_info = self.build_encl_disks_cache()
            if self.correct_mc_config:
                disk_data.update({"health": "", "disks_info": disks_info})
                self.build_system_persistent_cache()

                psu_data = storage_encl_health_json['hw']['fru']['psus']
                psus_info = self.build_encl_psus_cache()
                psu_data.update({"health": "", "psus_info": psus_info})

                cntrl_data = storage_encl_health_json['hw']['fru']['controllers']
                controllers_info = self.build_encl_controllers_cache()
                cntrl_data.update({"health": "", "controllers_info": controllers_info})

                fan_data = storage_encl_health_json['hw']['fru']['fans']
                fans_info = self.build_encl_fans_cache()
                fan_data.update({"health": "", "fans_info": fans_info})

                spln_data = storage_encl_health_json['hw']['fru']['sideplane_expander']
                sideplane_info = self.build_encl_sideplane_expander_cache()
                spln_data.update({"health": "", "sideplane_info": sideplane_info})

        elif category == 'sw':
            logvol_data = storage_encl_health_json['sw']['logical_volume']
            logicalvolume_info =  self.build_encl_logical_volume_cache()
            logvol_data.update(logicalvolume_info)

        elif category == 'interfaces':
            sas_port_data = storage_encl_health_json['interfaces']['sas_port']
            sas_port_info =  self.build_encl_sas_port_instances()
            sas_port_data.update({"health": "", "sas_port_info": sas_port_info})

        elif category == 'platform_sensors':
            ps_data = self.build_encl_platform_sensors_instances(self.sensor_list)
            if ps_data:
                for plsn in self.sensor_list:
                    sensor_data = storage_encl_health_json['platform_sensors'][plsn]
                    sensor_data.update({"health": "", plsn+"_info": ps_data[plsn]})

        if self.correct_mc_config:
            self.write_content_in_file(self.RESOURCE_HEALTH_VIEW_PATH, self._resource_health_view,
                                        'resource health view')
        
    def build_health_view_storage_jbod_cache(self, storage_encl_health_json):

        disk_data = storage_encl_health_json['hw']['fru']['disks']
        disks_info = self.build_jbod_disks_cache()
        disk_data.update({"health": "", "disks_info": disks_info})

        self.write_content_in_file(self.RESOURCE_HEALTH_VIEW_PATH, self._resource_health_view,
                                    'resource health view')

    def build_health_view_node_server_cache(self, node_health_json, category):

        ipmitool_cli = False

        if category == 'hw':
            hw_data = self.build_ipmi_fru_instances(self.ipmi_fru_lst)
            for fru in self.ipmi_fru_lst:
                if fru in hw_data:
                    ipmitool_cli = True
                    fru_data = node_health_json['hw']['fru'][fru+'s']
                    fru_data.update({"health": "", fru+"s_info": hw_data[fru]})

        elif category == 'platform_sensors':
            ps_data = self.build_ipmi_sensor_instances(self.sensor_list)
            for fru in self.sensor_list:
                if fru in ps_data:
                    ipmitool_cli = True
                    fru_data = node_health_json['platform_sensors'][fru]
                    fru_data.update({"health": "", fru+"_info": ps_data[fru]})

        elif category == 'interfaces':
            interfaces_data = self.build_node_interfaces_instances()
            for interface in self.node_interface_data:
                interface_data = node_health_json['interfaces'][interface]
                if interface == 'sas_port':
                    interface_data.update(interfaces_data[interface])
                else:
                    interface_data.update({"health": "", interface+"s_info": interfaces_data[interface]})
        
        elif category == 'os':
            os_sw_info = self.build_node_os_instances()
            for os_info in ['cortx_sw', 'operating_system']:
                os_data = node_health_json['os'][os_info]
                os_data.update(os_sw_info[os_info])

        if not ipmitool_cli and category not in ['interfaces', 'os']:
            print('Required ipmitool missing on Node to fetch %s data..!' % category)
            return False

        self.write_content_in_file(self.RESOURCE_HEALTH_VIEW_PATH, self._resource_health_view,
                                    'resource health view')

    def build_encl_disks_cache(self):
        """Retreive realstor disk info using cli api /show/disks"""

        disk_data = {}
        drives = self.get_realstor_show_data("drives")
        disks_existing_cache = True
        if drives:
            for drive in drives:
                slot = drive.get("slot", -1)
                if slot != -1:
                    resource_id = drive.get("durable-id")
                    durable_id = resource_id
                    health = drive.get("health", "NA")
                    serialno = drive.get("serial-number", "NA")
                    vendor = drive.get("vendor", "NA")
                    model = drive.get("model", "NA")
                    if health in self.undesired_vals:
                        health = "NA"
                    disk_data.update({
                        self.encl_disk_resource_type+'-'+resource_id: {
                            "alert_type": "NA",
                            "severity": "NA",
                            "alert_uuid": "NA",
                            "durable_id": durable_id,
                            "health": health,
                            "serial-number": serialno,
                            "vendor": vendor,
                            "model": model,
                            "fetch_time" : int(time.time())
                        }
                        })
                    dcache_path = self.encl_disks_filename + \
                                    "disk_{0}.json".format(slot)
                    if store.get(dcache_path) is None:
                        disks_existing_cache = False
                        store.put(drive, dcache_path)
            if not disks_existing_cache and self.correct_mc_config:
                print('Persistent cache does not exist, Building cache %s '\
                        % self.encl_disks_filename)
        return disk_data

    def build_jbod_disks_cache(self):
        """Retreive jbod disk info using dbus library"""

        bus = SystemBus()
        disk_systemd = bus.get_object('org.freedesktop.UDisks2', '/org/freedesktop/UDisks2')
        disk_manager = Interface(disk_systemd, dbus_interface='org.freedesktop.DBus.ObjectManager')
        disk_objects = disk_manager.GetManagedObjects()
        re_blocks = re.compile('(?P<path>.*?/block_devices/(?P<id>.*))')
        block_devs = [m.groupdict() for m in
                        [re_blocks.match(path) for path in list(disk_objects.keys())]
                        if m]

        drive_by_path = {}
        for block_dev in block_devs:
            try:
                if disk_objects[block_dev['path']].get('org.freedesktop.UDisks2.Block') is not None:
                    udisk_block = disk_objects[block_dev['path']]["org.freedesktop.UDisks2.Block"]
                    symlinks = self._sanitize_dbus_value(udisk_block["Symlinks"])
                    for symlink in symlinks:
                        if "by-path" in symlink:
                            drive_by_path[udisk_block["Drive"]] = symlink[len("/dev/disk/by-path/"):]
                    device = self._sanitize_dbus_value(udisk_block["Device"])
                    self.jbod_drive_by_device_name[udisk_block["Drive"]] = device
            except Exception as ae:
                print(ae)

        jbod_drives = {}
        jbod_cache = {}
        for obj_path, interfaces_and_property in disk_objects.items():
            if "drive" in obj_path and self._is_physical_drive(interfaces_and_property["org.freedesktop.UDisks2.Drive"]):
                jbod_cache.update({obj_path: False if self._is_drive_faulty(obj_path, interfaces_and_property) == "OK" else True})
                if not self._is_local_drive(interfaces_and_property):
                    drive_obj = interfaces_and_property["org.freedesktop.UDisks2.Drive"]
                    resource_id = drive_by_path.get(obj_path, str(drive_obj["Id"]))
                    jbod_drives.update({
                        self.encl_disk_resource_type+'-'+resource_id:{
                            "alert_type": "NA",
                            "severity": "NA",
                            "alert_uuid": "NA",
                            "durable_id": resource_id,
                            "health": self._is_drive_faulty(obj_path, interfaces_and_property),
                            "serial-number": str(drive_obj["Serial"]),
                            "vendor": str(drive_obj["Vendor"]),
                            "model": str(drive_obj["Model"]),
                            "fetch_time": int(time.time())
                        }
                    })
        if store.get(self.jbod_disks_filename) is None:
            print('Persistent cache does not exist, Building cache %s '\
                    % self.jbod_disks_filename)
            store.put(jbod_cache, self.jbod_disks_filename)

        return jbod_drives

    def build_encl_psus_cache(self):

        psu_data = {}
        psus_dict = {}
        psus = self.get_realstor_show_data("power-supplies")
        if psus:
            psus_existing_cache = True
            if store.get(self.encl_psus_filename) is None:
                print('Persistent cache does not exist, Building cache %s '\
                        % self.encl_psus_filename)
                psus_existing_cache = False
            for psu in psus:
                resource_id = psu.get("durable-id")
                durable_id = resource_id
                health = psu.get("health", "NA")
                serialno = psu.get("serial-number", "NA")
                vendor = psu.get("vendor", "NA")
                model = psu.get("model", "NA")
                if health in self.undesired_vals:
                    health = "NA"
                psu_data.update({
                        self.encl_psu_resource_type+'-'+resource_id: {
                            "alert_type": "NA",
                            "severity": "NA",
                            "alert_uuid": "NA",
                            "durable_id": durable_id,
                            "health": health,
                            "serial-number": serialno,
                            "vendor": vendor,
                            "model": model,
                            "fetch_time" : int(time.time())
                        }
                })
                if not psus_existing_cache:
                    alert_type = ""
                    if health != 'OK':
                        psus_dict.update({durable_id:{'health':health.lower(),
                                                    'alert_type':alert_type}})
            if not psus_existing_cache:
                store.put(psus_dict, self.encl_psus_filename)

        return psu_data

    def build_encl_controllers_cache(self):

        controller_data = {}
        controllers_dict = {}

        controllers = self.get_realstor_show_data("controllers")
        if controllers:
            controllers_existing_cache = True
            if store.get(self.encl_controllers_filename) is None:
                print('Persistent cache does not exist, Building cache %s '\
                        % self.encl_controllers_filename)
                controllers_existing_cache = False
            for controller in controllers:
                resource_id = controller.get("durable-id")
                durable_id = resource_id
                health = controller.get("health", "NA")
                serialno = controller.get("serial-number", "NA")
                vendor = controller.get("vendor", "NA")
                model = controller.get("model", "NA")
                if health in self.undesired_vals:
                    health = "NA"
                controller_data.update({
                        self.encl_controller_resource_type+'-'+resource_id: {
                            "alert_type": "NA",
                            "severity": "NA",
                            "alert_uuid": "NA",
                            "durable_id": durable_id,
                            "health": health,
                            "serial-number": serialno,
                            "vendor": vendor,
                            "model": model,
                            "fetch_time" : int(time.time())
                        }
                })
                if not controllers_existing_cache:
                    alert_type = ""
                    if health != 'OK':
                        controllers_dict.update({durable_id:{'health':health.lower(),
                                                            'alert_type':alert_type}})
            if not controllers_existing_cache:
                store.put(controllers_dict, self.encl_controllers_filename)
        return controller_data

    def build_encl_fans_cache(self):

        fan_data = {}
        fans_dict = {}

        fans = self.get_realstor_show_data("fan-modules")
        if fans:
            fans_existing_cache = True
            if store.get(self.encl_fans_filename) is None:
                print('Persistent cache does not exist, Building cache %s '\
                        % self.encl_fans_filename)
                fans_existing_cache = False
            for fan in fans:
                resource_id = fan.get("durable-id")
                durable_id = resource_id
                health = fan.get("health", "NA")
                serialno = fan.get("serial-number", "NA")
                vendor = fan.get("vendor", "NA")
                model = fan.get("model", "NA")
                if health in self.undesired_vals:
                    health = "NA"
                fan_data.update({
                        self.encl_fan_resource_type+'-'+resource_id: {
                            "alert_type": "NA",
                            "severity": "NA",
                            "alert_uuid": "NA",
                            "durable_id": durable_id,
                            "health": health,
                            "serial-number": serialno,
                            "vendor": vendor,
                            "model": model,
                            "fetch_time" : int(time.time())
                        }
                })
                if not fans_existing_cache:
                    alert_type = ""
                    if health != 'OK':
                        fans_dict.update({durable_id:alert_type})

            if not fans_existing_cache:
                store.put(fans_dict, self.encl_fans_filename)

        return fan_data

    def build_encl_sideplane_expander_cache(self):

        spln_data = {}
        sideplane_dict = {}
        sideplane_expanders = []
        encl_drawers = []

        encl_info = self.get_realstor_show_data("enclosures")
        if encl_info:
            spln_existing_cache = True
            if store.get(self.encl_sideplane_exp_filename) is None:
                print('Persistent cache does not exist, Building cache %s '\
                        % self.encl_sideplane_exp_filename)
                spln_existing_cache = False
            encl_drawers = encl_info[0]["drawers"]
            if encl_drawers:
                for drawer in encl_drawers:
                    sideplane_list = drawer["sideplanes"]
                    for sideplane in sideplane_list:
                        sideplane_expanders.append(sideplane)

            for spln in sideplane_expanders:
                resource_id = spln.get("durable-id")
                durable_id = resource_id
                health = spln.get("health", "NA")
                serialno = spln.get("serial-number", "NA")
                vendor = spln.get("vendor", "NA")
                model = spln.get("model", "NA")
                if health in self.undesired_vals:
                    health = "NA"
                spln_data.update({
                        self.encl_sideplane_resource_type+'-'+resource_id: {
                            "alert_type": "NA",
                            "severity": "NA",
                            "alert_uuid": "NA",
                            "durable_id": durable_id,
                            "health": health,
                            "serial-number": serialno,
                            "vendor": vendor,
                            "model": model,
                            "fetch_time" : int(time.time())
                        }
                })
                if not spln_existing_cache:
                    alert_type = ""
                    if health != 'OK':
                        sideplane_dict.update({durable_id:alert_type})

            if not spln_existing_cache:
                store.put(sideplane_dict, self.encl_sideplane_exp_filename)

        return spln_data

    def build_encl_logical_volume_cache(self):

        logvol_data = {}
        logicalvolume_dict = {}

        diskgroups = self.get_realstor_show_data("disk-groups")
        logicalvolumes = self.get_realstor_show_data("volumes")
        if logicalvolumes:
            logvol_existing_cache = True
            if store.get(self.encl_logical_volumes_filename) is None:
                print('Persistent cache does not exist, Building cache %s '\
                        % self.encl_logical_volumes_filename)
                logvol_existing_cache = False
            for logicalvolume in logicalvolumes:
                resource_id = logicalvolume.get("volume-name", "NA")
                durable_id = logicalvolume.get("virtual-disk-serial", "NA")
                health = logicalvolume.get("health", "NA")
                if health in self.undesired_vals:
                    health = "NA"
                logvol_data.update({
                        self.encl_logical_volume_resource_type+'-'+resource_id: {
                            "alert_type": "NA",
                            "severity": "NA",
                            "alert_uuid": "NA",
                            "durable_id": durable_id,
                            "health": health,
                            "fetch_time" : int(time.time())
                        }
                })
            if not logvol_existing_cache:
                for diskgroup in diskgroups:
                    health = diskgroup.get("health", "NA")
                    if health in self.undesired_vals:
                        health = "NA"
                    if health != 'OK':
                        serial_number = diskgroup.get("serial-number") # Disk Group Serial Number
                        alert_type = ""
                        logicalvolume_dict.update({serial_number:{'health':health.lower(),
                                                                'alert_type':alert_type}})

                store.put(logicalvolume_dict, self.encl_logical_volumes_filename)
        return logvol_data

    def build_encl_sas_port_instances(self):

        sas_data = {}
        sas_ports = self.get_realstor_show_data("sas-link-health")
        if sas_ports:
            for sas_port in sas_ports:
                resource_id = sas_port.get("durable-id")
                durable_id = resource_id
                health = sas_port.get("health", "NA")
                if health in self.undesired_vals:
                    health = "NA"
                sas_data.update({
                        self.encl_sas_resource_type+'-'+resource_id: {
                            "alert_type": "NA",
                            "severity": "NA",
                            "alert_uuid": "NA",
                            "durable_id": durable_id,
                            "health": health,
                            "fetch_time" : int(time.time())
                        }
                })

        return sas_data

    def build_encl_platform_sensors_instances(self, platform_sensors):

        sensors_data = {}
        sensors = self.get_realstor_show_data("sensor-status")
        if sensors:
            for platform_sensor in platform_sensors:
                resource_type = "enclosure:sensor:{0}".format(platform_sensor)
                plsn_data = {}
                for sensor in sensors:
                    if sensor['sensor-type'].lower() == platform_sensor:
                        resource_id = sensor.get("durable-id")
                        durable_id = resource_id
                        health = sensor.get("status", "NA")
                        if health in self.undesired_vals:
                            health = "NA"
                        plsn_data.update({
                                resource_type+'-'+resource_id: {
                                    "alert_type": "NA",
                                    "severity": "NA",
                                    "alert_uuid": "NA",
                                    "durable_id": durable_id,
                                    "health": health,
                                    "fetch_time" : int(time.time())
                                }
                        })

                sensors_data.update({platform_sensor: plsn_data})

        return sensors_data

    def build_system_persistent_cache(self):
        """Retreive realstor system state info using cli api /show/system"""

        system_existing_cache = True
        if store.get(singleton_realstorencl.faults_persistent_cache) is None:
            system_existing_cache = False

        if not system_existing_cache:
            system = self.get_realstor_show_data("system")
            if system:
                system = system[0]
                # Check if fault exists
                # TODO: use self.FAULT_KEY in system: system.key() generates
                # list and find item in that.
                if not singleton_realstorencl.FAULT_KEY in system.keys():
                    print("{0} Healthy, no faults seen".format(singleton_realstorencl.LDR_R1_ENCL))
                    return

                # Extract system faults and build memcache_faults
                print('Persistent cache does not exist, Building cache %s '\
                     % singleton_realstorencl.faults_persistent_cache)
                store.put(system[singleton_realstorencl.FAULT_KEY],
                    singleton_realstorencl.faults_persistent_cache)

    def build_encl_hw_specifics_instances(self):
        fan_module_list = []
        sideplane_list = []
        chassis_midplane_list = []
        enclosure_data = self.get_realstor_show_data(self.encl_hw_specifics_api)
        if enclosure_data and 'enclosure-fru' in enclosure_data and 'enclosures' in enclosure_data:
            for encl_fru in enclosure_data['enclosure-fru']:
                if encl_fru['name'] == 'FAN MODULE':
                    try:
                        fan_number = encl_fru['fru-location'].split()[-1]
                        for fan_module in enclosure_data['enclosures'][0]['fan-modules']:
                            if fan_module['durable-id'].split('.')[-1] == fan_number:
                                fan_module['part-number'] = encl_fru['part-number']
                                fan_module['serial-number'] = encl_fru['serial-number']
                                fan_module_list.append(fan_module)
                    except Exception as e:
                        print("Error while updating fan module {0} information : {1}".format(fan_number, e))
                elif encl_fru['name'] == 'SIDEPLANE':
                    encl_fru['object-name'] = encl_fru['name'].lower()
                    sideplane_list.append(encl_fru)
                elif encl_fru['name'] == 'CHASSIS_MIDPLANE':
                    encl_fru['object-name'] = encl_fru['name'].lower()
                    chassis_midplane_list.append(encl_fru)

            if len(fan_module_list) == len(enclosure_data['enclosures'][0]['fan-modules']):
                enclosure_data['enclosures'][0]['fan-modules'] = fan_module_list
            if sideplane_list:
                enclosure_data['enclosures'][0].update({'sideplane':sideplane_list})
            if chassis_midplane_list:
                enclosure_data['enclosures'][0].update({'chassis-midplane':chassis_midplane_list})
        return enclosure_data

    def write_content_in_file(self, file_path, file_data, instance):
        try:
            with open(file_path, 'w+') as fp:
                json.dump(file_data, fp,  indent=4)

        except Exception as e:
            print("Error in writing {0} file: {1}".format(instance, e))
            return False

    def get_realstor_show_data(self, fru):
        """Receives fru data from API.
           URL: http://<host>/api/show/<fru>
        """
        if fru == "controllers":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWCONTROLLERS
        elif fru == "fan-modules":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWFANMODULES
        elif fru == "power-supplies":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWPSUS
        elif fru == "drives":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWDISKS
        elif fru == "enclosures":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWENCLOSURE
        elif fru == "disk-groups":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWDISKGROUPS
        elif fru == "volumes":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWVOLUMES
        elif fru == "system":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWSYSTEM
        elif fru == "sensor-status":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWSENSORSTATUS
            fru = "sensors"
        elif fru == "sas-link-health":
            show_fru = singleton_realstorencl.URI_CLIAPI_SASHEALTHSTATUS
            fru = "expander-ports"
        elif fru == 'configuration':
            show_fru = "/show/configuration"

        response = self.fetch_ws_request_data(show_fru, fru)
        if response.status_code != singleton_realstorencl.ws.HTTP_OK:
            if (response.status_code == singleton_realstorencl.ws.HTTP_TIMEOUT or \
                response.status_code == singleton_realstorencl.ws.HTTP_CONN_REFUSED or \
                response.status_code == singleton_realstorencl.ws.HTTP_NO_ROUTE_TO_HOST) \
                and self.tried_alt_ip is False:
                print("Retrying to fetch data from another mc IP....: {}".format(singleton_realstorencl.active_ip))
                singleton_realstorencl.login()
                self.tried_alt_ip = True
                response = self.fetch_ws_request_data(show_fru, fru)
        
        if response.status_code != singleton_realstorencl.ws.HTTP_OK and self.tried_alt_ip is True:
            self.correct_mc_config = False
            return []
        else:
            response_data = json.loads(response.text)
            if fru == 'configuration':
                return response_data
            fru_data = response_data.get(fru)
            return fru_data

    def fetch_ws_request_data(self, show_fru, fru):

        url = singleton_realstorencl.build_url(show_fru)
        response = singleton_realstorencl.ws_request(url, singleton_realstorencl.ws.HTTP_GET)

        if not response:
            print("{0}:: {2} status unavailable as ws request {1}"
                " failed".format(singleton_realstorencl.LDR_R1_ENCL, url, fru))
            return response

        if response.status_code != singleton_realstorencl.ws.HTTP_OK:
            if url.find(singleton_realstorencl.ws.LOOPBACK) == -1:
                print("{0}:: http request {1} to get {3} failed with"
                    " err {2}".format(singleton_realstorencl.LDR_R1_ENCL, url, response.status_code, fru))
            return response

        return response

    def build_ipmi_fru_instances(self, frus):
        """Get the fru information based on fru_type and instance"""

        fru_id_map = self.get_fru_list_by_type(
            list(self.NODE_REQUEST_MAP.values()),
            sensor_id_map={})
        response = {}
        if fru_id_map:
            for fru in frus:
                resource_type = "node:fru:{0}".format(fru)
                fru_data = {}
                try:
                    fru_type = self.NODE_REQUEST_MAP.get(fru)
                    if fru_type not in fru_id_map:
                        continue
                    fru_dict = fru_id_map[fru_type]
                    for sensor_id in fru_dict.values():
                        if fru == 'fan':
                            fru_data.update({
                            resource_type+'-'+sensor_id:{
                                "alert_type": "NA",
                                "severity": "NA",
                                "alert_uuid": "NA",
                                "durable_id": "NA",
                                "health": "NA",
                                "fetch_time" : int(time.time())
                            }})
                            continue
                        if sensor_id == '':
                            continue
                        common, sensor_specific_info = self._executor.get_sensor_props(sensor_id)
                        # Converting Fru ID From "HDD 0 Status (0xf0)" to "Drive Slot / Bay #0xf0"
                        resource_id = fru_type+" #"+common['Sensor ID'].split('(')[1][:-1]
                        fru_data.update({
                            resource_type+'-'+resource_id:{
                                "alert_type": "NA",
                                "severity": "NA",
                                "alert_uuid": "NA",
                                "durable_id": "NA",
                                "health": "NA",
                                "fetch_time" : int(time.time())
                            }})
                except KeyError as e:
                    print('IPMIHealthView, _get_ipmi_fru_instances, \
                                    Unable to process the FRU type: %s' % e)
                    return response
                except Exception as e:
                    print('IPMIHealthView, _get_ipmi_fru_instances, \
                                    Error occured during request parsing %s' % e)
                    return response

                response.update({fru: fru_data})
        return response

    def build_ipmi_sensor_instances(self, sensors):
        """Get the sensor information based on sensor_type and instance"""

        sensor_id_map = self.get_fru_list_by_type(
            self.sensor_list,
            sensor_id_map={})
        response = {}
        if sensor_id_map:
            for sensor in sensors:
                resource_type = "node:sensor:{0}".format(sensor)
                sensor_data = {}
                try:
                    if sensor not in sensor_id_map:
                        continue
                    sensor_dict = sensor_id_map[sensor]
                    for sensor_id in sensor_dict.values():
                        if sensor_id == '':
                            continue
                        sensor_data.update({
                            resource_type+'-'+sensor_id:{
                                "alert_type": "NA",
                                "severity": "NA",
                                "alert_uuid": "NA",
                                "durable_id": "NA",
                                "health": "NA",
                                "fetch_time" : int(time.time())
                            }})
                except KeyError as e:
                    print('IPMIHealthView, _get_ipmi_sensor_instances, \
                                    Unable to process the Sensor type: %s' % e)
                    return response
                except Exception as e:
                    print('IPMIHealthView, _get_ipmi_sensor_instances, \
                                    Error occured during request parsing %s' % e)
                    return response

                response.update({sensor: sensor_data})
        return response

    def get_fru_list_by_type(self, fru_list, sensor_id_map):
        for fru in fru_list:
            fru_detail = self._executor.get_sensor_list_by_type(fru)
            if fru_detail:
                sensor_id_map[fru] = {fru_detail.index(fru): fru[0].strip()
                    for fru in fru_detail}
        return sensor_id_map

    def build_node_interfaces_instances(self):
        interfaces_json = {}
        for interface in self.node_interface_data:
            if interface == 'sas_port':
                sas_data_json = self.build_node_sas_port_instances()
                interfaces_json.update({interface:sas_data_json})
            if interface == 'network_cable':
                network_cable_json = self.build_node_network_cable_instances()
                interfaces_json.update({interface:network_cable_json})
        return interfaces_json

    def build_node_os_instances(self):

        os_sw_info_dict = {}
        cortx_build_version = 'NA'
        cortx_build_cmd = f"sudo salt-call pillar.get release:target_build --output=newline_values_only"
        try:
            subout = subprocess.Popen(cortx_build_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            result = subout.stdout.readlines()
            if result == [] or result == "":
                print("Unable to fetch cortx build version.")
            else:
                cortx_build_version = result[0].decode().rstrip('\n').split('/')[-2]
        except Exception as e:
            logger.error(f"Unable to fetch cortx build version. : {traceback.format_exc()}")
            print("Unable to fetch cortx build version.")
            print(e, traceback.format_exc())

        cluster_id = 'NA'
        cluster_id_cmd = f"sudo salt-call grains.get cluster_id --output=newline_values_only"
        try:
            subout = subprocess.Popen(cluster_id_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            result = subout.stdout.readlines()
            if result == [] or result == "":
                print("Unable to fetch cluster id.")
            else:
                cluster_id = result[0].decode().rstrip('\n')
        except Exception as e:
            logger.error(f"Unable to fetch cluster id. : {traceback.format_exc()}")
            print("Unable to fetch cluster id.")
            print(e, traceback.format_exc())

        os_sw_info_dict.update({'cortx_sw':{'version':cortx_build_version,
                                            'license-info': 'NA',
                                            'cluster-id':cluster_id}})

        os_serial = subprocess.Popen(['uname', '-rvmpio'], stdout=subprocess.PIPE).communicate()[0].decode("utf-8").rstrip()
        os_model = subprocess.Popen(['cat', '/etc/system-release'], stdout=subprocess.PIPE).communicate()[0].decode("utf-8").rstrip()
        os_sw_info_dict.update({'operating_system':{'version':os_model, 'system-info':os_serial}})

        return os_sw_info_dict

    def build_node_hw_specifics_instances(self):
        lshw_dict = {}
        with tempfile.TemporaryFile() as tempf:
            proc = subprocess.Popen(['lshw', '-json'], stdout=tempf)
            proc.wait()
            tempf.seek(0)
            str_dict = tempf.read().decode("utf-8")
            lshw_dict = json.loads(str_dict)

        return lshw_dict

    def build_node_sas_port_instances(self):
        sas_port_data = {}
        resource_type = "node:interface:sas"
        tool_factory = ToolFactory()
        utility_instance = tool_factory.get_instance('sysfs')
        utility_instance.initialize()
        sas_ports_dict = utility_instance.get_phy_negotiated_link_rate()
        sas_phy_dict = {}
        if sas_ports_dict:
            for key, value in sas_ports_dict.items():
                link_rate = value.strip()
                phy_number = int(key.split(":")[1])
                if 'Gbit'.lower() in link_rate.lower():
                    health = "OK"
                else:
                    health = "Fault"
                sas_phy_dict.update({phy_number:health})

            # For SASHBA-0
            if 'OK' in sas_phy_dict.values():
                sas_hba_health = "OK"
                sas_hba_severity = "NA"
                sas_hba_alert_type = "NA"
            else:
                sas_hba_health = "Fault"
                sas_hba_severity = "critical"
                sas_hba_alert_type = "fault"

            sas_port_data.update({
                'sas_hbas':{
                    resource_type+'-'+self.SAS_RESOURCE_ID:{
                        "alert_type": sas_hba_alert_type,
                        "severity": sas_hba_severity,
                        "alert_uuid": "NA",
                        "durable_id": "NA",
                        "health": sas_hba_health,
                        "fetch_time" : int(time.time())
                    }
                },
                'sas_ports':{}
            })

            # For SAS Port
            phy_lst_tpl = sorted([(k, v) for k, v in sas_phy_dict.items()])
            phy_hlt = [phy[1] for phy in phy_lst_tpl]
            # Make group of 4 phy for every port
            phy_group = [phy_hlt[n:n+4] for n in range(0, len(phy_hlt), 4)]
            for idx, phy_ports in enumerate(phy_group):
                if 'OK' in phy_ports:
                    sas_port_health = "OK"
                    sas_port_severity = "NA"
                    sas_port_alert_type = "NA"
                else:
                    sas_port_health = "Fault"
                    sas_port_severity = "critical"
                    sas_port_alert_type = "fault"
                sas_port_data['sas_ports'].update({
                    resource_type+':port-'+self.SAS_RESOURCE_ID+'-port-'+str(idx):{
                        "alert_type": sas_port_alert_type,
                        "severity": sas_port_severity,
                        "alert_uuid": "NA",
                        "durable_id": "NA",
                        "health": sas_port_health,
                        "fetch_time" : int(time.time())
                    }
                })

        return sas_port_data

    def build_node_network_cable_instances(self):
        network_cable_json = {}
        NW_CABLE_RESOURCE_TYPE = "node:interface:nw:cable"
        """Retrieves node information for the if_data json message"""
        net_data = psutil.net_io_counters(pernic=True)
        # Array to hold data about each network interface
        for interface in net_data.keys():
            nw_cable_conn_status = self.fetch_nw_cable_conn_status(interface)
            network_cable_json.update({
                    NW_CABLE_RESOURCE_TYPE+'-'+interface:{
                        "alert_type": "NA",
                        "severity": "NA",
                        "alert_uuid": "NA",
                        "durable_id": "NA",
                        "health": nw_cable_conn_status,
                        "fetch_time" : int(time.time())
                    }})

        return network_cable_json

    def fetch_nw_cable_conn_status(self, interface):
        phy_link_state = {'0':'Fault', '1':'OK', 'unknown':'NA'}
        carrier_indicator = 'unknown'
        try:
            with open(self.NW_CBL_CARRIER_FILE.format(interface)) as cFile:
                carrier_indicator = cFile.read().strip()
            if carrier_indicator not in phy_link_state.keys():
                carrier_indicator = 'unknown'
        except Exception as err:
            print("Node Data, unable to get cable connection state " +
                        f"of '{interface}'. {str(err)}")
        return phy_link_state[carrier_indicator]

    def _sanitize_dbus_value(self, value):
        """Convert certain DBus type combinations so that they are easier to read"""
        if isinstance(value, Array) and value.signature == "ay":
            try:
                return self._decode_ay(value)
            except:
                # Try an array of arrays; 'aay' which is the symlinks
                return list(map(self._decode_ay, value or ()))
        elif isinstance(value, Array) and value.signature == "y":
            return bytearray(value).rstrip(bytearray((0,))).decode('utf-8')
        else:
            return value

    def _decode_ay(self, value):
        """Convert binary blob from DBus queries to strings"""
        if len(value) == 0 or \
            value is None:
            return ''
        elif isinstance(value, str):
            return value
        elif isinstance(value, bytes):
            return value.decode('utf-8')
        else:
            return bytearray(value).rstrip(bytearray((0,))).decode('utf-8')

    def _is_physical_drive(self, interfaces_and_property):
        """If wwn starts with 0x5 then it is physical drive"""
        return interfaces_and_property["WWN"].startswith("0x5")

    def _is_local_drive(self, interfaces_and_property):
        return "org.freedesktop.UDisks2.Drive.Ata" in interfaces_and_property and \
            str(interfaces_and_property["org.freedesktop.UDisks2.Drive"]["Revision"]) != "G265"

    def _run_command(self, command):
        """Run the command and get the response and error returned"""
        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, encoding='utf-8')
        response, error = process.communicate()
        return response.rstrip('\n'), error.rstrip('\n')

    def _is_drive_faulty(self, path, interfaces_and_property):
        if self._is_local_drive(interfaces_and_property):
            cmd = f"sudo smartctl -H {self.jbod_drive_by_device_name[path]} --json"
        else:
            cmd = f"sudo smartctl -d scsi -H {self.jbod_drive_by_device_name[path]} --json"
        response, _ = self._run_command(cmd)
        response = json.loads(response)
        smart_status = response['smart_status']['passed']
        return 'OK' if smart_status else 'Fault'

    @staticmethod
    def _update_required_data_to_consul(args):
        
        base_info = {'/SYSTEM_INFORMATION/site_id': 'system_information/site_id',
                '/SYSTEM_INFORMATION/rack_id': 'system_information/rack_id',
                '/SYSTEM_INFORMATION/node_id': f'system_information/{node_key_id}/node_id',
                '/SYSTEM_INFORMATION/cluster_id': 'system_information/cluster_id',
                '/SYSTEM_INFORMATION/data_path': 'system_information/data_path'}

        if storage_type == 'rbod' and args.encl:
            base_info.update({
                '/STORAGE_ENCLOSURE/controller/primary_mc/ip': 'storage_enclosure/controller/primary_mc/ip',
                '/STORAGE_ENCLOSURE/controller/secondary_mc/ip': 'storage_enclosure/controller/secondary_mc/ip',
                '/STORAGE_ENCLOSURE/controller/primary_mc/port': 'storage_enclosure/controller/primary_mc/port',
                '/STORAGE_ENCLOSURE/controller/secondary_mc/port': 'storage_enclosure/controller/secondary_mc/port',
                '/STORAGE_ENCLOSURE/controller/user': 'storage_enclosure/controller/user',
                '/STORAGE_ENCLOSURE/controller/secret': 'storage_enclosure/controller/password'
            })
        host = os.getenv('CONSUL_HOST', CONSUL_HOST)
        port = os.getenv('CONSUL_PORT', CONSUL_PORT)
        print(f"Consul Host : {host}")
        print(f"Consul Port : {port}")
        sys_site_id = SITE_ID
        sys_rack_id = RACK_ID
        sys_node_id = NODE_ID
        sys_data_path = DATA_PATH
        try:
            consul_conn = consul.Consul(host=host, port=port)
            for key, value in base_info.items():
                try:
                    consul_value = consul_conn.kv.get(value)[1]["Value"].decode()
                    if key.endswith('site_id'):
                        sys_site_id = consul_value
                    elif key.endswith('rack_id'):
                        sys_rack_id = consul_value
                    elif key.endswith('node_id'):
                        sys_node_id = consul_value
                    elif key.endswith('cluster_id'):
                        sys_cluster_id = consul_value
                    elif key.endswith('data_path'):
                        sys_data_path = consul_value
                    consul_conn.kv.put(component+key, consul_value)

                except TypeError as e:
                    print(f"Unable get value from common config : {value} with error: {e}")
                    if key.endswith('site_id'):
                        consul_value = sys_site_id
                    elif key.endswith('rack_id'):
                        consul_value = sys_rack_id
                    elif key.endswith('node_id'):
                        consul_value = sys_node_id
                    elif key.endswith('data_path'):
                        consul_value = sys_data_path
                    else:
                        print("Exiting ...")
                        sys.exit(os.EX_USAGE)
                    print(f"Setting default value for {component+key} : {consul_value}")
                    consul_conn.kv.put(component+key, consul_value)
                print(f"Inserting common config {component+key}")

            return sys_site_id, sys_rack_id, sys_node_id, sys_cluster_id, sys_data_path
        except Exception as serror:
            print(f"Error in connecting consul: {serror}")
            print("Exiting ...")
            sys.exit(os.EX_USAGE)

if __name__ == "__main__":
    description = "Resource Health View Schema"
    parser = argparse.ArgumentParser(description=description, formatter_class=\
                argparse.RawDescriptionHelpFormatter, add_help=False, allow_abbrev=False)
    parser.add_argument("-h", "--help", action="store_true", help="Availabe arugumets")
    parser.add_argument("-n", "--node", action="store_true", help="fetch current node data")
    parser.add_argument("-e", "--encl", action="store_true", help="fetch current node enclouser data")
    parser.add_argument("-s", "--support", action="store_true", help="fetch support data")
    parser.add_argument("--path", metavar="<path> eg. --path '/tmp/sspl/'", help="Health view\
            schema destination path (Note: Path need to be already exist)")

    args = parser.parse_args()
    # Display help if no or invalid args are passed in
    if args.help or len(sys.argv) == 1 or \
        ('--path' in sys.argv and '/' not in sys.argv[sys.argv.index('--path')+1]):
        print('Missing arguments')
        parser.print_help()
        sys.exit(1)
    print(f"Storage Type : '{storage_type}'")
    print(f"Server Type '{server_type}'")

    if storage_type == 'virtual' and server_type == 'virtual':
        print("Resource health view is not supported in virtual server and virtual storage deployment")
        print("Exiting ...")
        sys.exit(os.EX_USAGE)

    sys_site_id, sys_rack_id, sys_node_id, sys_cluster_id, sys_data_path = \
        SSPLHealthView._update_required_data_to_consul(args)
    if storage_type == 'rbod' and args.encl:
        from framework.platforms.realstor.realstor_enclosure import singleton_realstorencl
    sys.exit(SSPLHealthView().run(args))
