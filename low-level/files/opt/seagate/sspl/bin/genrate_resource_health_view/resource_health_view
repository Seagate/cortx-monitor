#!/usr/bin/python3.6

import json
import os
import sys
import socket
import time
import argparse
import consul
import psutil
import warnings
warnings.filterwarnings(action='ignore',module='cryptography')

# Add the top level directories
op = os.path
parentdir = op.dirname(op.dirname(op.dirname(op.dirname(op.dirname(op.dirname(op.dirname(op.abspath(__file__))))))))
sys.path.insert(0, parentdir)
from framework.base.sspl_constants import component, CONSUL_HOST, CONSUL_PORT, node_key_id, PRODUCT_FAMILY
base_info = {'/SYSTEM_INFORMATION/site_id':'system_information/site_id',
             '/SYSTEM_INFORMATION/rack_id':'system_information/rack_id',
             '/SYSTEM_INFORMATION/node_id':f'system_information/{node_key_id}/node_id',
             '/SYSTEM_INFORMATION/cluster_id':'system_information/cluster_id',
             '/STORAGE_ENCLOSURE/controller/primary_mc/ip':'storage_enclosure/controller/primary_mc/ip',
             '/STORAGE_ENCLOSURE/controller/secondary_mc/ip':'storage_enclosure/controller/secondary_mc/ip',
             '/STORAGE_ENCLOSURE/controller/primary_mc/port':'storage_enclosure/controller/primary_mc/port',
             '/STORAGE_ENCLOSURE/controller/secondary_mc/port':'storage_enclosure/controller/secondary_mc/port',
             '/STORAGE_ENCLOSURE/controller/user':'storage_enclosure/controller/user',
             '/STORAGE_ENCLOSURE/controller/secret':'storage_enclosure/controller/password'}
host = os.getenv('CONSUL_HOST', CONSUL_HOST)
port = os.getenv('CONSUL_PORT', CONSUL_PORT)
try:
    consul_conn = consul.Consul(host=host, port=port)
    for key, value in base_info.items():
        value = consul_conn.kv.get(value)[1]["Value"].decode()
        consul_conn.kv.put(component+key, value)
except Exception as serror:
    print("Error in connecting consul: {}".format(serror))
    print("Exiting ...")
    sys.exit(os.EX_USAGE)
from framework.utils.store_factory import store
from framework.platforms.realstor.realstor_enclosure import singleton_realstorencl
from framework.utils.ipmi_client import IpmiFactory
from framework.utils.sysfs_interface import *

class SSPLHealthView(object):
    """docstring for SSPLHealthView"""

    persistent_data_location = singleton_realstorencl.vol_ras
    storage_encl_dir = persistent_data_location+'encl/frus/'

    encl_disks_filename = storage_encl_dir+'disks/'
    encl_psus_filename = storage_encl_dir+'psus/psudata.json'
    encl_controllers_filename = storage_encl_dir+'controllers/controllerdata.json'
    encl_fans_filename = storage_encl_dir+'fanmodules/fanmodule_data.json'
    encl_sideplane_exp_filename = storage_encl_dir+'sideplane_expanders/sideplane_expanders_data.json'
    encl_logical_volumes_filename = storage_encl_dir+'logical_volumes/logicalvolumedata.json'

    encl_disk_resource_type = "enclosure:fru:disk"
    encl_controller_resource_type = "enclosure:fru:controller"
    encl_fan_resource_type = "enclosure:fru:fan"
    encl_psu_resource_type = "enclosure:fru:psu"
    encl_sideplane_resource_type = "enclosure:fru:sideplane"
    encl_logical_volume_resource_type = f"enclosure:{PRODUCT_FAMILY}:logical_volume"
    encl_sas_resource_type = "enclosure:interface:sas"

    undesired_vals = ["N/A", ""]

    SITE_ID = singleton_realstorencl.site_id
    RACK_ID = singleton_realstorencl.rack_id
    HOST_NAME = socket.getfqdn()
    NODE_ID = singleton_realstorencl.node_id
    CLUSTER_ID = singleton_realstorencl.cluster_id
    RESOURCE_HEALTH_VIEW_FILE = 'resource_health_view.json'
    RESOURCE_HEALTH_VIEW_PATH = '/tmp/'+RESOURCE_HEALTH_VIEW_FILE
    TEMPLATE_SCHEMA_FILE = f'/opt/seagate/{PRODUCT_FAMILY}/sspl/bin/genrate_resource_health_view/resource_health_view_template.json'

    NODE_REQUEST_MAP = {
        "disk" : "Drive Slot / Bay",
        "fan" : "Fan",
        "psu" : "Power Supply"
    }
    SAS_RESOURCE_ID = "SASHBA-0"
    node_interface_data = ['sas_port', 'network_cable']
    NW_CBL_CARRIER_FILE = "/sys/class/net/{}/carrier"

    def __init__(self):

        self.fru_id_map = None
        self.sensor_id_map = None
        self.ipmi_fru_lst = ['disk', 'fan', 'psu']
        self.sensor_list = ['temperature', 'current', 'voltage']
        ipmi_factory = IpmiFactory()
        self._executor = ipmi_factory.get_implementor("ipmitool")
        try:
            self._resource_health_view = json.loads(open(self.TEMPLATE_SCHEMA_FILE).read())

        except Exception as e:
            print("Error in reading resource health view template file: {0}".format(e))
            sys.exit(1)

        self._resource_health_view['cluster'].update({'cluster_id':self.CLUSTER_ID})
        self._resource_health_view['cluster']['sites'][self.SITE_ID] =\
            self._resource_health_view['cluster']['sites'].pop('site_id')

        self._resource_health_view['cluster']['sites'][self.SITE_ID]['rack']\
            [self.RACK_ID] = self._resource_health_view['cluster']['sites']\
                [self.SITE_ID]['rack'].pop('rack_id')

    def run(self, parser):
        args = parser.parse_args()
        health_view_created = False
        # Display help if no or invalid args are passed in
        if args.help or len(sys.argv) == 1 or (len(sys.argv) == 3 and '--path' in sys.argv):
            print('Missing arguments')
            parser.print_help()
            sys.exit(1)

        if args.path:
            self.RESOURCE_HEALTH_VIEW_PATH = args.path
            if os.path.exists(args.path):
                self.RESOURCE_HEALTH_VIEW_PATH = args.path if args.path.endswith('/') else args.path+'/'
                self.RESOURCE_HEALTH_VIEW_PATH += self.RESOURCE_HEALTH_VIEW_FILE
            else:
                print("Given path doesn't exist")
                sys.exit(1)

        if os.path.exists(self.RESOURCE_HEALTH_VIEW_PATH):
            print("Resource Health view JSON file already exists, overriding ...!")

        if args.encl:
            try:
                storage_encl_health_json = self._resource_health_view['cluster']['sites']\
                                                    [self.SITE_ID]['rack'][self.RACK_ID]\
                                                    ['nodes']['storage_encl']
            except Exception as e:
                print("Error while extracting values from health view json % : " % e)
                return False
            self.build_health_view_storage_encl_cache(storage_encl_health_json, 'hw')
            self.build_health_view_storage_encl_cache(storage_encl_health_json, 'sw')
            self.build_health_view_storage_encl_cache(storage_encl_health_json, 'interfaces')
            self.build_health_view_storage_encl_cache(storage_encl_health_json, 'platform_sensors')
            health_view_created = True

        elif not args.encl:
            del self._resource_health_view['cluster']['sites']\
                                                    [self.SITE_ID]['rack'][self.RACK_ID]\
                                                    ['nodes']['storage_encl']

        if args.node:
            try:
                node_health_json = self._resource_health_view['cluster']['sites']\
                                                    [self.SITE_ID]['rack'][self.RACK_ID]\
                                                    ['nodes']['node:'+self.HOST_NAME] =\
                                                    self._resource_health_view['cluster']['sites']\
                                                    [self.SITE_ID]['rack'][self.RACK_ID]\
                                                    ['nodes'].pop('node')
                node_health_json.update({'node_id':self.NODE_ID})
            except Exception as e:
                print("Error while extracting values from health view json % : " % e)
                return False
            self.build_health_view_node_server_cache(node_health_json, 'hw')
            self.build_health_view_node_server_cache(node_health_json, 'platform_sensors')
            self.build_health_view_node_server_cache(node_health_json, 'interfaces')
            health_view_created = True

        elif not args.node:
            del self._resource_health_view['cluster']['sites']\
                                 [self.SITE_ID]['rack'][self.RACK_ID]\
                                 ['nodes']['node']

        try:
            with open(self.RESOURCE_HEALTH_VIEW_PATH, 'w+') as fp:
                json.dump(self._resource_health_view, fp,  indent=4)

        except Exception as e:
            print("Error in writing resource health view file: {0}".format(e))
            return False

        if health_view_created:
            print('Resource Health View Json Created Successfully..! :%s' % self.RESOURCE_HEALTH_VIEW_PATH)

    def build_health_view_storage_encl_cache(self, storage_encl_health_json, category):

        if category == 'hw':
            disk_data = storage_encl_health_json['hw']['fru']['disks']
            disks_info = self.build_encl_disks_cache()
            disk_data.update({"health": "", "disks_info": disks_info})
            self.build_system_persistent_cache()

            psu_data = storage_encl_health_json['hw']['fru']['psus']
            psus_info = self.build_encl_psus_cache()
            psu_data.update({"health": "", "psus_info": psus_info})

            cntrl_data = storage_encl_health_json['hw']['fru']['controllers']
            controllers_info = self.build_encl_controllers_cache()
            cntrl_data.update({"health": "", "controllers_info": controllers_info})

            fan_data = storage_encl_health_json['hw']['fru']['fans']
            fans_info = self.build_encl_fans_cache()
            fan_data.update({"health": "", "fans_info": fans_info})

            spln_data = storage_encl_health_json['hw']['fru']['sideplane_expander']
            sideplane_info = self.build_encl_sideplane_expander_cache()
            spln_data.update({"health": "", "sideplane_info": sideplane_info})

        elif category == 'sw':
            logvol_data = storage_encl_health_json['sw']['logical_volume']
            logicalvolume_info =  self.build_encl_logical_volume_cache()
            logvol_data.update(logicalvolume_info)

        elif category == 'interfaces':
            sas_port_data = storage_encl_health_json['interfaces']['sas_port']
            sas_port_info =  self.build_encl_sas_port_instances()
            sas_port_data.update({"health": "", "sas_port_info": sas_port_info})

        elif category == 'platform_sensors':
            ps_data = self.build_encl_platform_sensors_instances(self.sensor_list)
            for plsn in self.sensor_list:
                sensor_data = storage_encl_health_json['platform_sensors'][plsn]
                sensor_data.update({"health": "", plsn+"_info": ps_data[plsn]})


        try:
            with open(self.RESOURCE_HEALTH_VIEW_PATH, 'w+') as fp:
                json.dump(self._resource_health_view, fp,  indent=4)

        except Exception as e:
            print("Error in writing resource health view file: {0}".format(e))
            return False

    def build_health_view_node_server_cache(self, node_health_json, category):

        ipmitool_cli = False

        if category == 'hw':
            hw_data = self.build_ipmi_fru_instances(self.ipmi_fru_lst)
            for fru in self.ipmi_fru_lst:
                if fru in hw_data:
                    ipmitool_cli = True
                    fru_data = node_health_json['hw']['fru'][fru+'s']
                    fru_data.update({"health": "", fru+"s_info": hw_data[fru]})

        elif category == 'platform_sensors':
            ps_data = self.build_ipmi_sensor_instances(self.sensor_list)
            for fru in self.sensor_list:
                if fru in ps_data:
                    ipmitool_cli = True
                    fru_data = node_health_json['platform_sensors'][fru]
                    fru_data.update({"health": "", fru+"_info": ps_data[fru]})

        elif category == 'interfaces':
            interfaces_data = self.build_node_interfaces_instances()
            for interface in self.node_interface_data:
                interface_data = node_health_json['interfaces'][interface]
                interface_data.update({"health": "", interface+"s_info": interfaces_data[interface]})

        if not ipmitool_cli and category != 'interfaces':
            print('Required ipmitool missing on Node to fetch %s data..!' % category)
            return False

        try:
            with open(self.RESOURCE_HEALTH_VIEW_PATH, 'w+') as fp:
                json.dump(self._resource_health_view, fp,  indent=4)

        except Exception as e:
            print("Error in writing resource health view file: {0}".format(e))
            return False


    def build_encl_disks_cache(self):
        """Retreive realstor disk info using cli api /show/disks"""

        disk_data = {}
        drives = self.get_realstor_show_data("drives")
        disks_existing_cache = True

        for drive in drives:
            slot = drive.get("slot", -1)

            if slot != -1:
                resource_id = drive.get("durable-id")
                durable_id = resource_id
                health = drive.get("health", "NA")
                if health in self.undesired_vals:
                    health = "NA"
                disk_data.update({
                    self.encl_disk_resource_type+'-'+resource_id: {
                        "alert_type": "NA",
                        "severity": "NA",
                        "alert_uuid": "NA",
                        "durable_id": durable_id,
                        "health": health,
                        "fetch_time" : int(time.time())
                    }
                    })
                dcache_path = self.encl_disks_filename + \
                                 "disk_{0}.json".format(slot)
                if store.get(dcache_path) is None:
                    disks_existing_cache = False
                    store.put(drive, dcache_path)
        if not disks_existing_cache:
            print('Persistent cache does not exist, Building cache %s '\
                    % self.encl_disks_filename)
        return disk_data

    def build_encl_psus_cache(self):

        psus_existing_cache = True
        if store.get(self.encl_psus_filename) is None:
            print('Persistent cache does not exist, Building cache %s '\
                    % self.encl_psus_filename)
            psus_existing_cache = False

        psu_data = {}
        psus_dict = {}

        psus = self.get_realstor_show_data("power-supplies")

        for psu in psus:
            resource_id = psu.get("durable-id")
            durable_id = resource_id
            health = psu.get("health", "NA")
            if health in self.undesired_vals:
                health = "NA"
            psu_data.update({
                    self.encl_psu_resource_type+'-'+resource_id: {
                        "alert_type": "NA",
                        "severity": "NA",
                        "alert_uuid": "NA",
                        "durable_id": durable_id,
                        "health": health,
                        "fetch_time" : int(time.time())
                    }
            })
            if not psus_existing_cache:
                alert_type = ""
                if health != 'OK':
                    psus_dict.update({durable_id:{'health':health.lower(),
                                                  'alert_type':alert_type}})
        if not psus_existing_cache:
            store.put(psus_dict, self.encl_psus_filename)

        return psu_data

    def build_encl_controllers_cache(self):

        controllers_existing_cache = True
        if store.get(self.encl_controllers_filename) is None:
            print('Persistent cache does not exist, Building cache %s '\
                    % self.encl_controllers_filename)
            controllers_existing_cache = False

        controller_data = {}
        controllers_dict = {}

        controllers = self.get_realstor_show_data("controllers")

        for controller in controllers:
            resource_id = controller.get("durable-id")
            durable_id = resource_id
            health = controller.get("health", "NA")
            if health in self.undesired_vals:
                health = "NA"
            controller_data.update({
                    self.encl_controller_resource_type+'-'+resource_id: {
                        "alert_type": "NA",
                        "severity": "NA",
                        "alert_uuid": "NA",
                        "durable_id": durable_id,
                        "health": health,
                        "fetch_time" : int(time.time())
                    }
            })
            if not controllers_existing_cache:
                alert_type = ""
                if health != 'OK':
                    controllers_dict.update({durable_id:{'health':health.lower(),
                                                         'alert_type':alert_type}})
        if not controllers_existing_cache:
            store.put(controllers_dict, self.encl_controllers_filename)
        return controller_data

    def build_encl_fans_cache(self):

        fans_existing_cache = True
        if store.get(self.encl_fans_filename) is None:
            print('Persistent cache does not exist, Building cache %s '\
                    % self.encl_fans_filename)
            fans_existing_cache = False

        fan_data = {}
        fans_dict = {}

        fans = self.get_realstor_show_data("fan-modules")

        for fan in fans:
            resource_id = fan.get("durable-id")
            durable_id = resource_id
            health = fan.get("health", "NA")
            if health in self.undesired_vals:
                health = "NA"
            fan_data.update({
                    self.encl_fan_resource_type+'-'+resource_id: {
                        "alert_type": "NA",
                        "severity": "NA",
                        "alert_uuid": "NA",
                        "durable_id": durable_id,
                        "health": health,
                        "fetch_time" : int(time.time())
                    }
            })
            if not fans_existing_cache:
                alert_type = ""
                if health != 'OK':
                    fans_dict.update({durable_id:alert_type})

        if not fans_existing_cache:
            store.put(fans_dict, self.encl_fans_filename)

        return fan_data

    def build_encl_sideplane_expander_cache(self):

        spln_existing_cache = True
        if store.get(self.encl_sideplane_exp_filename) is None:
            print('Persistent cache does not exist, Building cache %s '\
                    % self.encl_sideplane_exp_filename)
            spln_existing_cache = False

        spln_data = {}
        sideplane_dict = {}
        sideplane_expanders = []

        encl_info = self.get_realstor_show_data("enclosures")
        encl_drawers = encl_info[0]["drawers"]
        if encl_drawers:
            for drawer in encl_drawers:
                sideplane_list = drawer["sideplanes"]
                for sideplane in sideplane_list:
                     sideplane_expanders.append(sideplane)

        for spln in sideplane_expanders:
            resource_id = spln.get("durable-id")
            durable_id = resource_id
            health = spln.get("health", "NA")
            if health in self.undesired_vals:
                health = "NA"
            spln_data.update({
                    self.encl_sideplane_resource_type+'-'+resource_id: {
                        "alert_type": "NA",
                        "severity": "NA",
                        "alert_uuid": "NA",
                        "durable_id": durable_id,
                        "health": health,
                        "fetch_time" : int(time.time())
                    }
            })
            if not spln_existing_cache:
                alert_type = ""
                if health != 'OK':
                    sideplane_dict.update({durable_id:alert_type})

        if not spln_existing_cache:
            store.put(sideplane_dict, self.encl_sideplane_exp_filename)

        return spln_data

    def build_encl_logical_volume_cache(self):

        logvol_existing_cache = True
        if store.get(self.encl_logical_volumes_filename) is None:
            print('Persistent cache does not exist, Building cache %s '\
                    % self.encl_logical_volumes_filename)
            logvol_existing_cache = False

        logvol_data = {}
        logicalvolume_dict = {}

        diskgroups = self.get_realstor_show_data("disk-groups")
        logicalvolumes = self.get_realstor_show_data("volumes")

        for logicalvolume in logicalvolumes:
            resource_id = logicalvolume.get("volume-name", "NA")
            durable_id = logicalvolume.get("virtual-disk-serial", "NA")
            health = logicalvolume.get("health", "NA")
            if health in self.undesired_vals:
                health = "NA"
            logvol_data.update({
                    self.encl_logical_volume_resource_type+'-'+resource_id: {
                        "alert_type": "NA",
                        "severity": "NA",
                        "alert_uuid": "NA",
                        "durable_id": durable_id,
                        "health": health,
                        "fetch_time" : int(time.time())
                    }
            })
        if not logvol_existing_cache:
            for diskgroup in diskgroups:
                health = diskgroup.get("health", "NA")
                if health in self.undesired_vals:
                    health = "NA"
                if health != 'OK':
                    serial_number = diskgroup.get("serial-number") # Disk Group Serial Number
                    alert_type = ""
                    logicalvolume_dict.update({serial_number:{'health':health.lower(),
                                                              'alert_type':alert_type}})

            store.put(logicalvolume_dict, self.encl_logical_volumes_filename)
        return logvol_data

    def build_encl_sas_port_instances(self):

        sas_data = {}
        sas_ports = self.get_realstor_show_data("sas-link-health")

        for sas_port in sas_ports:
            resource_id = sas_port.get("durable-id")
            durable_id = resource_id
            health = sas_port.get("health", "NA")
            if health in self.undesired_vals:
                health = "NA"
            sas_data.update({
                    self.encl_sas_resource_type+'-'+resource_id: {
                        "alert_type": "NA",
                        "severity": "NA",
                        "alert_uuid": "NA",
                        "durable_id": durable_id,
                        "health": health,
                        "fetch_time" : int(time.time())
                    }
            })

        return sas_data

    def build_encl_platform_sensors_instances(self, platform_sensors):

        sensors_data = {}
        sensors = self.get_realstor_show_data("sensor-status")

        for platform_sensor in platform_sensors:
            resource_type = "enclosure:sensor:{0}".format(platform_sensor)
            plsn_data = {}
            for sensor in sensors:
                if sensor['sensor-type'].lower() == platform_sensor:
                    resource_id = sensor.get("durable-id")
                    durable_id = resource_id
                    health = sensor.get("status", "NA")
                    if health in self.undesired_vals:
                        health = "NA"
                    plsn_data.update({
                            resource_type+'-'+resource_id: {
                                "alert_type": "NA",
                                "severity": "NA",
                                "alert_uuid": "NA",
                                "durable_id": durable_id,
                                "health": health,
                                "fetch_time" : int(time.time())
                            }
                    })

            sensors_data.update({platform_sensor: plsn_data})

        return sensors_data

    def build_system_persistent_cache(self):
        """Retreive realstor system state info using cli api /show/system"""

        system_existing_cache = True
        if store.get(singleton_realstorencl.faults_persistent_cache) is None:
            print('Persistent cache does not exist, Building cache %s '\
                     % singleton_realstorencl.faults_persistent_cache)
            system_existing_cache = False

        if not system_existing_cache:
            system = self.get_realstor_show_data("system")[0]
            if system:
                # Check if fault exists
                # TODO: use self.FAULT_KEY in system: system.key() generates
                # list and find item in that.
                if not singleton_realstorencl.FAULT_KEY in system.keys():
                    print("{0} Healthy, no faults seen".format(singleton_realstorencl.EES_ENCL))
                    return

                # Extract system faults and build memcache_faults
                store.put(system[singleton_realstorencl.FAULT_KEY],
                    singleton_realstorencl.faults_persistent_cache)

    def get_realstor_show_data(self, fru):
        """Receives fru data from API.
           URL: http://<host>/api/show/<fru>
        """
        if fru == "controllers":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWCONTROLLERS
        elif fru == "fan-modules":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWFANMODULES
        elif fru == "power-supplies":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWPSUS
        elif fru == "drives":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWDISKS
        elif fru == "enclosures":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWENCLOSURE
        elif fru == "disk-groups":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWDISKGROUPS
        elif fru == "volumes":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWVOLUMES
        elif fru == "system":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWSYSTEM
        elif fru == "sensor-status":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWSENSORSTATUS
            fru = "sensors"
        elif fru == "sas-link-health":
            show_fru = singleton_realstorencl.URI_CLIAPI_SASHEALTHSTATUS
            fru = "expander-ports"

        url = singleton_realstorencl.build_url(show_fru)

        response = singleton_realstorencl.ws_request(url, singleton_realstorencl.ws.HTTP_GET)

        if not response:
            print("{0}:: {2} status unavailable as ws request {1}"
                " failed".format(singleton_realstorencl.EES_ENCL, url, fru))
            return

        if response.status_code != singleton_realstorencl.ws.HTTP_OK:
            if url.find(singleton_realstorencl.ws.LOOPBACK) == -1:
                print("{0}:: http request {1} to get {3} failed with"
                    " err {2}".format(singleton_realstorencl.EES_ENCL, url, response.status_code, fru))
            return

        response_data = json.loads(response.text)
        fru_data = response_data.get(fru)
        return fru_data

    def build_ipmi_fru_instances(self, frus):
        """Get the fru information based on fru_type and instance"""

        fru_id_map = self.get_fru_list_by_type(
            list(self.NODE_REQUEST_MAP.values()),
            sensor_id_map={})
        response = {}
        if fru_id_map:
            for fru in frus:
                resource_type = "node:fru:{0}".format(fru)
                fru_data = {}
                try:
                    fru_type = self.NODE_REQUEST_MAP.get(fru)
                    if fru_type not in fru_id_map:
                        continue
                    fru_dict = fru_id_map[fru_type]
                    for sensor_id in fru_dict.values():
                        if fru == 'fan':
                            fru_data.update({
                            resource_type+'-'+sensor_id:{
                                "alert_type": "NA",
                                "severity": "NA",
                                "alert_uuid": "NA",
                                "durable_id": "NA",
                                "health": "NA",
                                "fetch_time" : int(time.time())
                            }})
                            continue
                        if sensor_id == '':
                            continue
                        common, sensor_specific_info = self._executor.get_sensor_props(sensor_id)
                        # Converting Fru ID From "HDD 0 Status (0xf0)" to "Drive Slot / Bay #0xf0"
                        resource_id = fru_type+" #"+common['Sensor ID'].split('(')[1][:-1]
                        fru_data.update({
                            resource_type+'-'+resource_id:{
                                "alert_type": "NA",
                                "severity": "NA",
                                "alert_uuid": "NA",
                                "durable_id": "NA",
                                "health": "NA",
                                "fetch_time" : int(time.time())
                            }})
                except KeyError as e:
                    print('IPMIHealthView, _get_ipmi_fru_instances, \
                                    Unable to process the FRU type: %s' % e)
                    return response
                except Exception as e:
                    print('IPMIHealthView, _get_ipmi_fru_instances, \
                                    Error occured during request parsing %s' % e)
                    return response

                response.update({fru: fru_data})
        return response

    def build_ipmi_sensor_instances(self, sensors):
        """Get the sensor information based on sensor_type and instance"""

        sensor_id_map = self.get_fru_list_by_type(
            self.sensor_list,
            sensor_id_map={})
        response = {}
        if sensor_id_map:
            for sensor in sensors:
                resource_type = "node:sensor:{0}".format(sensor)
                sensor_data = {}
                try:
                    if sensor not in sensor_id_map:
                        continue
                    sensor_dict = sensor_id_map[sensor]
                    for sensor_id in sensor_dict.values():
                        if sensor_id == '':
                            continue
                        sensor_data.update({
                            resource_type+'-'+sensor_id:{
                                "alert_type": "NA",
                                "severity": "NA",
                                "alert_uuid": "NA",
                                "durable_id": "NA",
                                "health": "NA",
                                "fetch_time" : int(time.time())
                            }})
                except KeyError as e:
                    print('IPMIHealthView, _get_ipmi_sensor_instances, \
                                    Unable to process the Sensor type: %s' % e)
                    return response
                except Exception as e:
                    print('IPMIHealthView, _get_ipmi_sensor_instances, \
                                    Error occured during request parsing %s' % e)
                    return response

                response.update({sensor: sensor_data})
        return response

    def get_fru_list_by_type(self, fru_list, sensor_id_map):
        for fru in fru_list:
            fru_detail = self._executor.get_sensor_list_by_type(fru)
            if fru_detail:
                sensor_id_map[fru] = {fru_detail.index(fru): fru[0].strip()
                    for fru in fru_detail}
        return sensor_id_map

    def build_node_interfaces_instances(self):
        interfaces_json = {}
        for interface in self.node_interface_data:
            if interface == 'sas_port':
                sas_data_json = self.build_node_sas_port_instances()
                interfaces_json.update({interface:sas_data_json})
            if interface == 'network_cable':
                network_cable_json = self.build_node_network_cable_instances()
                interfaces_json.update({interface:network_cable_json})
        return interfaces_json

    def build_node_sas_port_instances(self):
        sas_port_data = {}
        resource_type = "node:interface:sas"
        tool_factory = ToolFactory()
        utility_instance = tool_factory.get_instance('sysfs')
        utility_instance.initialize()
        sas_ports_dict = utility_instance.get_phy_negotiated_link_rate()
        if sas_ports_dict:
            for key, value in sas_ports_dict.items():
                link_rate = value.strip()
                phy_number = key.split(":")[1]
                resource_id = self.SAS_RESOURCE_ID + ':' + "phy-" + phy_number
                if 'Gbit'.lower() in link_rate.lower():
                    health = "OK"
                elif 'Unknown'.lower() in link_rate.lower():
                    health = "NA"
                else:
                    health = "Fault"

                sas_port_data.update({
                    resource_type+'-'+resource_id:{
                        "alert_type": "NA",
                        "severity": "NA",
                        "alert_uuid": "NA",
                        "durable_id": "NA",
                        "health": health,
                        "fetch_time" : int(time.time())
                    }})
        return sas_port_data

    def build_node_network_cable_instances(self):
        network_cable_json = {}
        NW_CABLE_RESOURCE_TYPE = "node:interface:nw:cable"
        """Retrieves node information for the if_data json message"""
        net_data = psutil.net_io_counters(pernic=True)
        # Array to hold data about each network interface
        for interface in net_data.keys():
            nw_cable_conn_status = self.fetch_nw_cable_conn_status(interface)
            network_cable_json.update({
                    NW_CABLE_RESOURCE_TYPE+'-'+interface:{
                        "alert_type": "NA",
                        "severity": "NA",
                        "alert_uuid": "NA",
                        "durable_id": "NA",
                        "health": nw_cable_conn_status,
                        "fetch_time" : int(time.time())
                    }})

        return network_cable_json

    def fetch_nw_cable_conn_status(self, interface):
        phy_link_state = {'0':'Fault', '1':'OK', 'unknown':'NA'}
        carrier_indicator = 'unknown'
        try:
            with open(self.NW_CBL_CARRIER_FILE.format(interface)) as cFile:
                carrier_indicator = cFile.read().strip()
            if carrier_indicator not in phy_link_state.keys():
                carrier_indicator = 'unknown'
        except Exception as err:
            print("Node Data, unable to get cable connection state " +
                        f"of '{interface}'. {str(err)}")
        return phy_link_state[carrier_indicator]

if __name__ == "__main__":
    description = "Resource Health View Schema"
    parser = argparse.ArgumentParser(description=description, formatter_class=\
                argparse.RawDescriptionHelpFormatter, add_help=False, allow_abbrev=False)
    parser.add_argument("-h", "--help", action="store_true", help="Availabe arugumets")
    parser.add_argument("-n", "--node", action="store_true", help="fetch current node data")
    parser.add_argument("-e", "--encl", action="store_true", help="fetch current node enclouser data")
    parser.add_argument("--path", metavar="<path> eg. --path '/tmp/sspl/'", help="Health view\
            schema destination path (Note: Path need to be already exist)")

    sys.exit(SSPLHealthView().run(parser))
