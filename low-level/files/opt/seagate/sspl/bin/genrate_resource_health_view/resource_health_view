#!/usr/bin/python3.6

import json
import os
import sys
import socket
import time
import argparse
import consul
import psutil
import subprocess
import tempfile
import warnings
warnings.filterwarnings(action='ignore',module='cryptography')

# Add the top level directories
op = os.path
parentdir = op.dirname(op.dirname(op.dirname(op.dirname(op.dirname(op.dirname(op.dirname(op.abspath(__file__))))))))
sys.path.insert(0, parentdir)
from framework.base.sspl_constants import component, CONSUL_HOST, CONSUL_PORT, node_key_id
base_info = {'/SYSTEM_INFORMATION/site_id':'system_information/site_id',
             '/SYSTEM_INFORMATION/rack_id':'system_information/rack_id',
             '/SYSTEM_INFORMATION/node_id':f'system_information/{node_key_id}/node_id',
             '/SYSTEM_INFORMATION/cluster_id':'system_information/cluster_id',
             '/STORAGE_ENCLOSURE/controller/primary_mc/ip':'storage_enclosure/controller/primary_mc/ip',
             '/STORAGE_ENCLOSURE/controller/secondary_mc/ip':'storage_enclosure/controller/secondary_mc/ip',
             '/STORAGE_ENCLOSURE/controller/primary_mc/port':'storage_enclosure/controller/primary_mc/port',
             '/STORAGE_ENCLOSURE/controller/secondary_mc/port':'storage_enclosure/controller/secondary_mc/port',
             '/STORAGE_ENCLOSURE/controller/user':'storage_enclosure/controller/user',
             '/STORAGE_ENCLOSURE/controller/secret':'storage_enclosure/controller/password'}
host = os.getenv('CONSUL_HOST', CONSUL_HOST)
port = os.getenv('CONSUL_PORT', CONSUL_PORT)
try:
    consul_conn = consul.Consul(host=host, port=port)
    for key, value in base_info.items():
        value = consul_conn.kv.get(value)[1]["Value"].decode()
        consul_conn.kv.put(component+key, value)
except Exception as serror:
    print("Error in connecting consul: {}".format(serror))
    print("Exiting ...")
    sys.exit(os.EX_USAGE)
from framework.utils.store_factory import store
from framework.platforms.realstor.realstor_enclosure import singleton_realstorencl
from framework.utils.ipmi_client import IpmiFactory

class SSPLHealthView(object):
    """docstring for SSPLHealthView"""

    persistent_data_location = singleton_realstorencl.vol_ras
    storage_encl_dir = persistent_data_location+'encl/frus/'

    encl_disks_filename = storage_encl_dir+'disks/'
    encl_psus_filename = storage_encl_dir+'psus/psudata.json'
    encl_controllers_filename = storage_encl_dir+'controllers/controllerdata.json'
    encl_fans_filename = storage_encl_dir+'fanmodules/fanmodule_data.json'
    encl_sideplane_exp_filename = storage_encl_dir+'sideplane_expanders/sideplane_expanders_data.json'
    encl_logical_volumes_filename = storage_encl_dir+'logical_volumes/logicalvolumedata.json'

    encl_disk_resource_type = "enclosure:fru:disk"
    encl_controller_resource_type = "enclosure:fru:controller"
    encl_fan_resource_type = "enclosure:fru:fan"
    encl_psu_resource_type = "enclosure:fru:psu"
    encl_sideplane_resource_type = "enclosure:fru:sideplane"
    encl_logical_volume_resource_type = "enclosure:eos:logical_volume"
    encl_sas_resource_type = "enclosure:interface:sas"

    undesired_vals = ["N/A", ""]

    SITE_ID = singleton_realstorencl.site_id
    RACK_ID = singleton_realstorencl.rack_id
    HOST_NAME = socket.getfqdn()
    NODE_ID = singleton_realstorencl.node_id
    CLUSTER_ID = singleton_realstorencl.cluster_id
    RESOURCE_HEALTH_VIEW_FILE = 'resource_health_view.json'
    RESOURCE_HEALTH_VIEW_PATH = '/tmp/'+RESOURCE_HEALTH_VIEW_FILE
    TEMPLATE_SCHEMA_FILE = '/opt/seagate/eos/sspl/bin/genrate_resource_health_view/resource_health_view_template.json'

    NODE_REQUEST_MAP = {
        "disk" : "Drive Slot / Bay",
        "fan" : "Fan",
        "psu" : "Power Supply"
    }
    
    encl_hw_specifics_api = 'configuration'
    ENCL_MANIFEST_PATH = '/tmp/encl_manifest.json'
    NODE_MANIFEST_PATH = '/tmp/node_manifest.json'

    def __init__(self):

        self.fru_id_map = None
        self.sensor_id_map = None
        self.ipmi_fru_lst = ['disk', 'fan', 'psu']
        self.sensor_list = ['temperature', 'current', 'voltage']
        ipmi_factory = IpmiFactory()
        self._executor = ipmi_factory.get_implementor("ipmitool")
        try:
            self._resource_health_view = json.loads(open(self.TEMPLATE_SCHEMA_FILE).read())

        except Exception as e:
            print("Error in reading resource health view template file: {0}".format(e))
            sys.exit(1)

        self._resource_health_view['cluster'].update({'cluster_id':self.CLUSTER_ID})
        self._resource_health_view['cluster']['sites'][self.SITE_ID] =\
            self._resource_health_view['cluster']['sites'].pop('site_id')

        self._resource_health_view['cluster']['sites'][self.SITE_ID]['rack']\
            [self.RACK_ID] = self._resource_health_view['cluster']['sites']\
                [self.SITE_ID]['rack'].pop('rack_id')

    def run(self, parser):
        args = parser.parse_args()
        health_view_created = False
        # Display help if no or invalid args are passed in
        if args.help or len(sys.argv) == 1 or \
            ('--path' in sys.argv and '/' not in sys.argv[sys.argv.index('--path')+1]):
            print('Missing arguments')
            parser.print_help()
            sys.exit(1)

        if args.path:
            self.RESOURCE_HEALTH_VIEW_PATH = args.path
            if os.path.exists(args.path):
                self.RESOURCE_HEALTH_VIEW_PATH = args.path if args.path.endswith('/') else args.path+'/'
                if args.support and args.encl:
                    self.ENCL_MANIFEST_PATH = self.RESOURCE_HEALTH_VIEW_PATH + "encl_manifest.json"
                if args.support and args.node:
                    self.NODE_MANIFEST_PATH = self.RESOURCE_HEALTH_VIEW_PATH + "node_manifest.json"
                if not args.support:
                    self.RESOURCE_HEALTH_VIEW_PATH += self.RESOURCE_HEALTH_VIEW_FILE
            else:
                print("Given path doesn't exist")
                sys.exit(1)

        if not args.support:
            if os.path.exists(self.RESOURCE_HEALTH_VIEW_PATH):
                print("Resource Health view JSON file already exists, overriding ...!")

            if args.encl:
                try:
                    storage_encl_health_json = self._resource_health_view['cluster']['sites']\
                                                        [self.SITE_ID]['rack'][self.RACK_ID]\
                                                        ['nodes']['storage_encl']
                except Exception as e:
                    print("Error while extracting values from health view json % : " % e)
                    return False
                self.build_health_view_storage_encl_cache(storage_encl_health_json, 'hw')
                self.build_health_view_storage_encl_cache(storage_encl_health_json, 'sw')
                self.build_health_view_storage_encl_cache(storage_encl_health_json, 'interfaces')
                self.build_health_view_storage_encl_cache(storage_encl_health_json, 'platform_sensors')
                health_view_created = True

            elif not args.encl:
                del self._resource_health_view['cluster']['sites']\
                                                        [self.SITE_ID]['rack'][self.RACK_ID]\
                                                        ['nodes']['storage_encl']

            if args.node:
                try:
                    node_health_json = self._resource_health_view['cluster']['sites']\
                                                        [self.SITE_ID]['rack'][self.RACK_ID]\
                                                        ['nodes']['node:'+self.HOST_NAME] =\
                                                        self._resource_health_view['cluster']['sites']\
                                                        [self.SITE_ID]['rack'][self.RACK_ID]\
                                                        ['nodes'].pop('node')
                    node_health_json.update({'node_id':self.NODE_ID})
                except Exception as e:
                    print("Error while extracting values from health view json % : " % e)
                    return False
                self.build_health_view_node_server_cache(node_health_json, 'hw')
                self.build_health_view_node_server_cache(node_health_json, 'platform_sensors')
                health_view_created = True

            elif not args.node:
                del self._resource_health_view['cluster']['sites']\
                                    [self.SITE_ID]['rack'][self.RACK_ID]\
                                    ['nodes']['node']

            self.write_content_in_file(self.RESOURCE_HEALTH_VIEW_PATH, self._resource_health_view,
                                        'resource health view')

            if health_view_created:
                print('Resource Health View Json Created Successfully..! :%s' % self.RESOURCE_HEALTH_VIEW_PATH)

        else:
            support_common_data = {
                "cluster_id": self.CLUSTER_ID,
                "site_id": self.SITE_ID,
                "rack_id": self.RACK_ID,
                "node_id": self.NODE_ID
            }
            if args.encl and args.support:
                encl_support_data = {}
                encl_support_data.update(support_common_data)
                encl_data_response = self.build_encl_hw_specifics_instances()
                if 'enclosures' in encl_data_response:
                    encl_support_data["enclosure_wwn"] = encl_data_response["enclosures"][0]["enclosure-wwn"]
                else:
                    encl_support_data["enclosure_wwn"] = "enclosure"
                encl_support_data["hw_specifics"] = encl_data_response
                self.write_content_in_file(self.ENCL_MANIFEST_PATH, encl_support_data,
                                            'enclosure support data')
                print('Enclosure Support data Json Created Successfully..! :%s' % self.ENCL_MANIFEST_PATH)
            if args.node and args.support:
                node_support_data = {}
                node_support_data.update(support_common_data)
                node_support_data.update({"hostname": self.HOST_NAME})
                node_support_data["hw_specifics"] = self.build_node_hw_specifics_instances()
                self.write_content_in_file(self.NODE_MANIFEST_PATH, node_support_data,
                                            'node support data')
                print('Node Support data Json Created Successfully..! :%s' % self.NODE_MANIFEST_PATH)

    def build_health_view_storage_encl_cache(self, storage_encl_health_json, category):

        if category == 'hw':
            disk_data = storage_encl_health_json['hw']['fru']['disks']
            disks_info = self.build_encl_disks_cache()
            disk_data.update({"health": "", "disks_info": disks_info})
            self.build_system_persistent_cache()

            psu_data = storage_encl_health_json['hw']['fru']['psus']
            psus_info = self.build_encl_psus_cache()
            psu_data.update({"health": "", "psus_info": psus_info})

            cntrl_data = storage_encl_health_json['hw']['fru']['controllers']
            controllers_info = self.build_encl_controllers_cache()
            cntrl_data.update({"health": "", "controllers_info": controllers_info})

            fan_data = storage_encl_health_json['hw']['fru']['fans']
            fans_info = self.build_encl_fans_cache()
            fan_data.update({"health": "", "fans_info": fans_info})

            spln_data = storage_encl_health_json['hw']['fru']['sideplane_expander']
            sideplane_info = self.build_encl_sideplane_expander_cache()
            spln_data.update({"health": "", "sideplane_info": sideplane_info})

        elif category == 'sw':
            logvol_data = storage_encl_health_json['sw']['logical_volume']
            logicalvolume_info =  self.build_encl_logical_volume_cache()
            logvol_data.update(logicalvolume_info)

        elif category == 'interfaces':
            sas_port_data = storage_encl_health_json['interfaces']['sas_port']
            sas_port_info =  self.build_encl_sas_port_instances()
            sas_port_data.update({"health": "", "sas_port_info": sas_port_info})

        elif category == 'platform_sensors':
            ps_data = self.build_encl_platform_sensors_instances(self.sensor_list)
            for plsn in self.sensor_list:
                sensor_data = storage_encl_health_json['platform_sensors'][plsn]
                sensor_data.update({"health": "", plsn+"_info": ps_data[plsn]})

        self.write_content_in_file(self.RESOURCE_HEALTH_VIEW_PATH, self._resource_health_view,
                                    'resource health view')

    def build_health_view_node_server_cache(self, node_health_json, category):

        ipmitool_cli = False

        if category == 'hw':
            hw_data = self.build_ipmi_fru_instances(self.ipmi_fru_lst)
            for fru in self.ipmi_fru_lst:
                if fru in hw_data:
                    ipmitool_cli = True
                    fru_data = node_health_json['hw']['fru'][fru+'s']
                    fru_data.update({"health": "", fru+"s_info": hw_data[fru]})

        elif category == 'platform_sensors':
            ps_data = self.build_ipmi_sensor_instances(self.sensor_list)
            for fru in self.sensor_list:
                if fru in ps_data:
                    ipmitool_cli = True
                    fru_data = node_health_json['platform_sensors'][fru]
                    fru_data.update({"health": "", fru+"_info": ps_data[fru]})

        if not ipmitool_cli:
            print('Required ipmitool missing on Node to fetch %s data..!' % category)
            return False

        self.write_content_in_file(self.RESOURCE_HEALTH_VIEW_PATH, self._resource_health_view,
                                    'resource health view')


    def build_encl_disks_cache(self):
        """Retreive realstor disk info using cli api /show/disks"""

        disk_data = {}
        drives = self.get_realstor_show_data("drives")
        disks_existing_cache = True

        for drive in drives:
            slot = drive.get("slot", -1)

            if slot != -1:
                resource_id = drive.get("durable-id")
                durable_id = resource_id
                health = drive.get("health", "NA")
                if health in self.undesired_vals:
                    health = "NA"
                disk_data.update({
                    self.encl_disk_resource_type+'-'+resource_id: {
                        "alert_type": "NA",
                        "severity": "NA",
                        "alert_uuid": "NA",
                        "durable_id": durable_id,
                        "health": health,
                        "fetch_time" : int(time.time())
                    }
                    })
                dcache_path = self.encl_disks_filename + \
                                 "disk_{0}.json".format(slot)
                if store.get(dcache_path) is None:
                    disks_existing_cache = False
                    store.put(drive, dcache_path)
        if not disks_existing_cache:
            print('Persistent cache does not exist, Building cache %s '\
                    % self.encl_disks_filename)
        return disk_data

    def build_encl_psus_cache(self):

        psus_existing_cache = True
        if store.get(self.encl_psus_filename) is None:
            print('Persistent cache does not exist, Building cache %s '\
                    % self.encl_psus_filename)
            psus_existing_cache = False

        psu_data = {}
        psus_dict = {}

        psus = self.get_realstor_show_data("power-supplies")

        for psu in psus:
            resource_id = psu.get("durable-id")
            durable_id = resource_id
            health = psu.get("health", "NA")
            if health in self.undesired_vals:
                health = "NA"
            psu_data.update({
                    self.encl_psu_resource_type+'-'+resource_id: {
                        "alert_type": "NA",
                        "severity": "NA",
                        "alert_uuid": "NA",
                        "durable_id": durable_id,
                        "health": health,
                        "fetch_time" : int(time.time())
                    }
            })
            if not psus_existing_cache:
                alert_type = ""
                if health != 'OK':
                    psus_dict.update({durable_id:{'health':health.lower(),
                                                  'alert_type':alert_type}})
        if not psus_existing_cache:
            store.put(psus_dict, self.encl_psus_filename)

        return psu_data

    def build_encl_controllers_cache(self):

        controllers_existing_cache = True
        if store.get(self.encl_controllers_filename) is None:
            print('Persistent cache does not exist, Building cache %s '\
                    % self.encl_controllers_filename)
            controllers_existing_cache = False

        controller_data = {}
        controllers_dict = {}

        controllers = self.get_realstor_show_data("controllers")

        for controller in controllers:
            resource_id = controller.get("durable-id")
            durable_id = resource_id
            health = controller.get("health", "NA")
            if health in self.undesired_vals:
                health = "NA"
            controller_data.update({
                    self.encl_controller_resource_type+'-'+resource_id: {
                        "alert_type": "NA",
                        "severity": "NA",
                        "alert_uuid": "NA",
                        "durable_id": durable_id,
                        "health": health,
                        "fetch_time" : int(time.time())
                    }
            })
            if not controllers_existing_cache:
                alert_type = ""
                if health != 'OK':
                    controllers_dict.update({durable_id:{'health':health.lower(),
                                                         'alert_type':alert_type}})
        if not controllers_existing_cache:
            store.put(controllers_dict, self.encl_controllers_filename)
        return controller_data

    def build_encl_fans_cache(self):

        fans_existing_cache = True
        if store.get(self.encl_fans_filename) is None:
            print('Persistent cache does not exist, Building cache %s '\
                    % self.encl_fans_filename)
            fans_existing_cache = False

        fan_data = {}
        fans_dict = {}

        fans = self.get_realstor_show_data("fan-modules")

        for fan in fans:
            resource_id = fan.get("durable-id")
            durable_id = resource_id
            health = fan.get("health", "NA")
            if health in self.undesired_vals:
                health = "NA"
            fan_data.update({
                    self.encl_fan_resource_type+'-'+resource_id: {
                        "alert_type": "NA",
                        "severity": "NA",
                        "alert_uuid": "NA",
                        "durable_id": durable_id,
                        "health": health,
                        "fetch_time" : int(time.time())
                    }
            })
            if not fans_existing_cache:
                alert_type = ""
                if health != 'OK':
                    fans_dict.update({durable_id:alert_type})

        if not fans_existing_cache:
            store.put(fans_dict, self.encl_fans_filename)

        return fan_data

    def build_encl_sideplane_expander_cache(self):

        spln_existing_cache = True
        if store.get(self.encl_sideplane_exp_filename) is None:
            print('Persistent cache does not exist, Building cache %s '\
                    % self.encl_sideplane_exp_filename)
            spln_existing_cache = False

        spln_data = {}
        sideplane_dict = {}
        sideplane_expanders = []

        encl_info = self.get_realstor_show_data("enclosures")
        encl_drawers = encl_info[0]["drawers"]
        if encl_drawers:
            for drawer in encl_drawers:
                sideplane_list = drawer["sideplanes"]
                for sideplane in sideplane_list:
                     sideplane_expanders.append(sideplane)

        for spln in sideplane_expanders:
            resource_id = spln.get("durable-id")
            durable_id = resource_id
            health = spln.get("health", "NA")
            if health in self.undesired_vals:
                health = "NA"
            spln_data.update({
                    self.encl_sideplane_resource_type+'-'+resource_id: {
                        "alert_type": "NA",
                        "severity": "NA",
                        "alert_uuid": "NA",
                        "durable_id": durable_id,
                        "health": health,
                        "fetch_time" : int(time.time())
                    }
            })
            if not spln_existing_cache:
                alert_type = ""
                if health != 'OK':
                    sideplane_dict.update({durable_id:alert_type})

        if not spln_existing_cache:
            store.put(sideplane_dict, self.encl_sideplane_exp_filename)

        return spln_data

    def build_encl_logical_volume_cache(self):

        logvol_existing_cache = True
        if store.get(self.encl_logical_volumes_filename) is None:
            print('Persistent cache does not exist, Building cache %s '\
                    % self.encl_logical_volumes_filename)
            logvol_existing_cache = False

        logvol_data = {}
        logicalvolume_dict = {}

        diskgroups = self.get_realstor_show_data("disk-groups")
        logicalvolumes = self.get_realstor_show_data("volumes")

        for logicalvolume in logicalvolumes:
            resource_id = logicalvolume.get("volume-name", "NA")
            durable_id = logicalvolume.get("virtual-disk-serial", "NA")
            health = logicalvolume.get("health", "NA")
            if health in self.undesired_vals:
                health = "NA"
            logvol_data.update({
                    self.encl_logical_volume_resource_type+'-'+resource_id: {
                        "alert_type": "NA",
                        "severity": "NA",
                        "alert_uuid": "NA",
                        "durable_id": durable_id,
                        "health": health,
                        "fetch_time" : int(time.time())
                    }
            })
        if not logvol_existing_cache:
            for diskgroup in diskgroups:
                health = diskgroup.get("health", "NA")
                if health in self.undesired_vals:
                    health = "NA"
                if health != 'OK':
                    serial_number = diskgroup.get("serial-number") # Disk Group Serial Number
                    alert_type = ""
                    logicalvolume_dict.update({serial_number:{'health':health.lower(),
                                                              'alert_type':alert_type}})

            store.put(logicalvolume_dict, self.encl_logical_volumes_filename)
        return logvol_data

    def build_encl_sas_port_instances(self):

        sas_data = {}
        sas_ports = self.get_realstor_show_data("sas-link-health")

        for sas_port in sas_ports:
            resource_id = sas_port.get("durable-id")
            durable_id = resource_id
            health = sas_port.get("health", "NA")
            if health in self.undesired_vals:
                health = "NA"
            sas_data.update({
                    self.encl_sas_resource_type+'-'+resource_id: {
                        "alert_type": "NA",
                        "severity": "NA",
                        "alert_uuid": "NA",
                        "durable_id": durable_id,
                        "health": health,
                        "fetch_time" : int(time.time())
                    }
            })

        return sas_data

    def build_encl_platform_sensors_instances(self, platform_sensors):

        sensors_data = {}
        sensors = self.get_realstor_show_data("sensor-status")

        for platform_sensor in platform_sensors:
            resource_type = "enclosure:sensor:{0}".format(platform_sensor)
            plsn_data = {}
            for sensor in sensors:
                if sensor['sensor-type'].lower() == platform_sensor:
                    resource_id = sensor.get("durable-id")
                    durable_id = resource_id
                    health = sensor.get("status", "NA")
                    if health in self.undesired_vals:
                        health = "NA"
                    plsn_data.update({
                            resource_type+'-'+resource_id: {
                                "alert_type": "NA",
                                "severity": "NA",
                                "alert_uuid": "NA",
                                "durable_id": durable_id,
                                "health": health,
                                "fetch_time" : int(time.time())
                            }
                    })

            sensors_data.update({platform_sensor: plsn_data})

        return sensors_data

    def build_system_persistent_cache(self):
        """Retreive realstor system state info using cli api /show/system"""

        system_existing_cache = True
        if store.get(singleton_realstorencl.faults_persistent_cache) is None:
            print('Persistent cache does not exist, Building cache %s '\
                     % singleton_realstorencl.faults_persistent_cache)
            system_existing_cache = False

        if not system_existing_cache:
            system = self.get_realstor_show_data("system")[0]
            if system:
                # Check if fault exists
                # TODO: use self.FAULT_KEY in system: system.key() generates
                # list and find item in that.
                if not singleton_realstorencl.FAULT_KEY in system.keys():
                    print("{0} Healthy, no faults seen".format(singleton_realstorencl.EES_ENCL))
                    return

                # Extract system faults and build memcache_faults
                store.put(system[singleton_realstorencl.FAULT_KEY],
                    singleton_realstorencl.faults_persistent_cache)

    def build_encl_hw_specifics_instances(self):
        return self.get_realstor_show_data(self.encl_hw_specifics_api)

    def write_content_in_file(self, file_path, file_data, instance):
        try:
            with open(file_path, 'w+') as fp:
                json.dump(file_data, fp,  indent=4)

        except Exception as e:
            print("Error in writing {0} file: {1}".format(instance, e))
            return False

    def get_realstor_show_data(self, fru):
        """Receives fru data from API.
           URL: http://<host>/api/show/<fru>
        """
        if fru == "controllers":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWCONTROLLERS
        elif fru == "fan-modules":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWFANMODULES
        elif fru == "power-supplies":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWPSUS
        elif fru == "drives":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWDISKS
        elif fru == "enclosures":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWENCLOSURE
        elif fru == "disk-groups":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWDISKGROUPS
        elif fru == "volumes":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWVOLUMES
        elif fru == "system":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWSYSTEM
        elif fru == "sensor-status":
            show_fru = singleton_realstorencl.URI_CLIAPI_SHOWSENSORSTATUS
            fru = "sensors"
        elif fru == "sas-link-health":
            show_fru = singleton_realstorencl.URI_CLIAPI_SASHEALTHSTATUS
            fru = "expander-ports"
        elif fru == 'configuration':
            show_fru = "/show/configuration"

        url = singleton_realstorencl.build_url(show_fru)

        response = singleton_realstorencl.ws_request(url, singleton_realstorencl.ws.HTTP_GET)

        if not response:
            print("{0}:: {2} status unavailable as ws request {1}"
                " failed".format(singleton_realstorencl.EES_ENCL, url, fru))
            return

        if response.status_code != singleton_realstorencl.ws.HTTP_OK:
            if url.find(singleton_realstorencl.ws.LOOPBACK) == -1:
                print("{0}:: http request {1} to get {3} failed with"
                    " err {2}".format(singleton_realstorencl.EES_ENCL, url, response.status_code, fru))
            return

        response_data = json.loads(response.text)
        if fru == 'configuration':
            return response_data
        fru_data = response_data.get(fru)
        return fru_data

    def build_ipmi_fru_instances(self, frus):
        """Get the fru information based on fru_type and instance"""

        fru_id_map = self.get_fru_list_by_type(
            list(self.NODE_REQUEST_MAP.values()),
            sensor_id_map={})
        response = {}
        if fru_id_map:
            for fru in frus:
                resource_type = "node:fru:{0}".format(fru)
                fru_data = {}
                try:
                    fru_type = self.NODE_REQUEST_MAP.get(fru)
                    if fru_type not in fru_id_map:
                        continue
                    fru_dict = fru_id_map[fru_type]
                    for sensor_id in fru_dict.values():
                        if fru == 'fan':
                            fru_data.update({
                            resource_type+'-'+sensor_id:{
                                "alert_type": "NA",
                                "severity": "NA",
                                "alert_uuid": "NA",
                                "durable_id": "NA",
                                "health": "NA",
                                "fetch_time" : int(time.time())
                            }})
                            continue
                        if sensor_id == '':
                            continue
                        common, sensor_specific_info = self._executor.get_sensor_props(sensor_id)
                        # Converting Fru ID From "HDD 0 Status (0xf0)" to "Drive Slot / Bay #0xf0"
                        resource_id = fru_type+" #"+common['Sensor ID'].split('(')[1][:-1]
                        fru_data.update({
                            resource_type+'-'+resource_id:{
                                "alert_type": "NA",
                                "severity": "NA",
                                "alert_uuid": "NA",
                                "durable_id": "NA",
                                "health": "NA",
                                "fetch_time" : int(time.time())
                            }})
                except KeyError as e:
                    print('IPMIHealthView, _get_ipmi_fru_instances, \
                                    Unable to process the FRU type: %s' % e)
                    return response
                except Exception as e:
                    print('IPMIHealthView, _get_ipmi_fru_instances, \
                                    Error occured during request parsing %s' % e)
                    return response

                response.update({fru: fru_data})
        return response

    def build_ipmi_sensor_instances(self, sensors):
        """Get the sensor information based on sensor_type and instance"""

        sensor_id_map = self.get_fru_list_by_type(
            self.sensor_list,
            sensor_id_map={})
        response = {}
        if sensor_id_map:
            for sensor in sensors:
                resource_type = "node:sensor:{0}".format(sensor)
                sensor_data = {}
                try:
                    if sensor not in sensor_id_map:
                        continue
                    sensor_dict = sensor_id_map[sensor]
                    for sensor_id in sensor_dict.values():
                        if sensor_id == '':
                            continue
                        sensor_data.update({
                            resource_type+'-'+sensor_id:{
                                "alert_type": "NA",
                                "severity": "NA",
                                "alert_uuid": "NA",
                                "durable_id": "NA",
                                "health": "NA",
                                "fetch_time" : int(time.time())
                            }})
                except KeyError as e:
                    print('IPMIHealthView, _get_ipmi_sensor_instances, \
                                    Unable to process the Sensor type: %s' % e)
                    return response
                except Exception as e:
                    print('IPMIHealthView, _get_ipmi_sensor_instances, \
                                    Error occured during request parsing %s' % e)
                    return response

                response.update({sensor: sensor_data})
        return response

    def get_fru_list_by_type(self, fru_list, sensor_id_map):
        for fru in fru_list:
            fru_detail = self._executor.get_sensor_list_by_type(fru)
            if fru_detail:
                sensor_id_map[fru] = {fru_detail.index(fru): fru[0].strip()
                    for fru in fru_detail}
        return sensor_id_map

    def build_node_hw_specifics_instances(self):
        lshw_dict = {}
        with tempfile.TemporaryFile() as tempf:
            proc = subprocess.Popen(['lshw', '-json'], stdout=tempf)
            proc.wait()
            tempf.seek(0)
            str_dict = tempf.read().decode("utf-8")
            lshw_dict = json.loads(str_dict)
        return lshw_dict

if __name__ == "__main__":
    description = "Resource Health View Schema"
    parser = argparse.ArgumentParser(description=description, formatter_class=\
                argparse.RawDescriptionHelpFormatter, add_help=False, allow_abbrev=False)
    parser.add_argument("-h", "--help", action="store_true", help="Availabe arugumets")
    parser.add_argument("-n", "--node", action="store_true", help="fetch current node data")
    parser.add_argument("-e", "--encl", action="store_true", help="fetch current node enclouser data")
    parser.add_argument("-s", "--support", action="store_true", help="fetch support data")
    parser.add_argument("--path", metavar="<path> eg. --path '/tmp/sspl/'", help="Health view\
            schema destination path (Note: Path need to be already exist)")

    sys.exit(SSPLHealthView().run(parser))